# logger output path
log_path: "scripts/run.log"

cache:
    dataset_repo: "kh4dien/fineweb-100m-sample"
    dataset_split: "train[:15%]"

    # tokens_per_batch per batch is minibatch_size * batch_len. n_batches is n_tokens // tokens_per_batch
    minibatch_size: 300
    batch_len: 64

    # width of the autoencoder
    n_features: 32768

    # n_tokens we'd like to process
    n_tokens: 8_000_000

    # shuffle token seed for reproducibility
    seed: 22

example:
    l_ctx: 15
    r_ctx: 4

cot_explainer: 
    temperature: 0.0
    max_tokens: 1000
    l: "<<"
    r: ">>"

simple_explainer:
    temperature: 0.0
    max_tokens: 100

detection:
    max_tokens: 1000
    temperature: 0.0
    n_batches: 5
    seed: 22
    batch_size: 10
    threshold: 0.3
    n_incorrect: 2

generation: 
    n_tests: 10
    temperature: 0.0