# logger output path
log_path: "scripts/run.log"

cache:
    dataset_repo: "stas/openwebtext-10k"
    dataset_split: "train"

    # tokens_per_batch per batch is minibatch_size * batch_len. n_batches is n_tokens // tokens_per_batch
    minibatch_size: 64
    batch_len: 64

    # width of the autoencoder
    n_features: 32768

    # n_tokens we'd like to process
    n_tokens: 10_240_000

    # shuffle token seed for reproducibility
    seed: 22

example:
    l_ctx: 15
    r_ctx: 4

cot_explainer: 
    temperature: 0.0
    max_tokens: 1000
    l: "<<"
    r: ">>"

simple_explainer:
    temperature: 0.0
    max_tokens: 100

detection:
    max_tokens: 1000
    temperature: 0.0
    n_batches: 5
    seed: 22
    batch_size: 10

generation: 
    n_tests: 10
    temperature: 0.0