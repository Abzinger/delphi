{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.conda/envs/autointerp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sae_auto_interp.config import ExperimentConfig, FeatureConfig\n",
    "from sae_auto_interp.features import (\n",
    "    FeatureDataset,\n",
    "    FeatureLoader\n",
    ")\n",
    "from sae_auto_interp.features.constructors import default_constructor\n",
    "from sae_auto_interp.features.samplers import sample\n",
    "\n",
    "feat_layer = 32\n",
    "sae_model = \"gemma/131k\"\n",
    "module = f\".model.layers.{feat_layer}\"\n",
    "n_train, n_test, n_quantiles = 5, 10, 5\n",
    "n_feats = 300\n",
    "feature_dict = {f\"{module}\": torch.arange(0, n_feats)}\n",
    "feature_cfg = FeatureConfig(width=131072, n_splits=5, max_examples=100000, min_examples=200)\n",
    "experiment_cfg = ExperimentConfig(n_random=0, example_ctx_len=64, n_quantiles=5, n_examples_test=0, n_examples_train=n_train + n_test // n_quantiles, train_type=\"quantiles\", test_type=\"even\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/rpj-v2-sample  train[:1%]\n"
     ]
    }
   ],
   "source": [
    "from sae_auto_interp.features import FeatureDataset\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "dataset = FeatureDataset(\n",
    "        raw_dir=f\"/mnt/ssd-1/gpaulo/SAE-Zoology/raw_features/{sae_model}\",\n",
    "        cfg=feature_cfg,\n",
    "        modules=[module],\n",
    "        features=feature_dict,\n",
    ")\n",
    "\n",
    "constructor=partial(\n",
    "            default_constructor,\n",
    "            tokens=dataset.tokens,\n",
    "            n_random=experiment_cfg.n_random, \n",
    "            ctx_len=experiment_cfg.example_ctx_len, \n",
    "            max_examples=feature_cfg.max_examples\n",
    "        )\n",
    "\n",
    "sampler=partial(sample,cfg=experiment_cfg)\n",
    "loader = FeatureLoader(dataset, constructor=constructor, sampler=sampler)\n",
    "    \n",
    "record = next(iter(loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:01<00:00,  7.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "\n",
    "subject_device = \"cuda:6\"\n",
    "\n",
    "subject_name = \"google/gemma-2-9b\"\n",
    "subject = AutoModelForCausalLM.from_pretrained(subject_name).to(subject_device)\n",
    "subject_tokenizer = AutoTokenizer.from_pretrained(subject_name)\n",
    "subject_tokenizer.pad_token = subject_tokenizer.eos_token\n",
    "subject.config.pad_token_id = subject_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 24/24 [00:26<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "scorer_device = \"cuda:7\"\n",
    "scorer_name = \"google/gemma-2-27b\"\n",
    "scorer = AutoModelForCausalLM.from_pretrained(\n",
    "    scorer_name,\n",
    "    device_map={\"\": scorer_device},\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    )\n",
    ")\n",
    "scorer_tokenizer = AutoTokenizer.from_pretrained(scorer_name)\n",
    "scorer_tokenizer.pad_token = scorer_tokenizer.eos_token\n",
    "scorer.config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "scorer.generation_config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "\n",
    "# explainer is the same model as the scorer\n",
    "explainer_device = scorer_device\n",
    "explainer = scorer\n",
    "explainer_tokenizer = scorer_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\n",
      "\n",
      "For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\n",
      "\n",
      "The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\n",
      "\n",
      "Neuron 1\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.05)\n",
      "\n",
      "<PROMPT>I like to eat</PROMPT>\n",
      "Most increased tokens: ' fro' (+0.14), ' fruit' (+0.13), ' oranges' (+0.11), ' bananas' (+0.1), ' strawberries' (+0.03)\n",
      "\n",
      "Explanation: fruits\n",
      "\n",
      "Neuron 2\n",
      "<PROMPT>Once</PROMPT>\n",
      "Most increased tokens: ' upon' (+0.22), ' in' (+0.2), ' a' (+0.05), ' long' (+0.04)\n",
      "\n",
      "<PROMPT>Ryan Quarles\\n\\nRyan Francis Quarles (born October 20, 1983)</PROMPT>\n",
      "Most increased tokens: ' once' (+0.03), ' happily' (+0.31), ' for' (+0.01)\n",
      "\n",
      "<PROMPT>MSI Going Full Throttle @ CeBIT</PROMPT>\n",
      "Most increased tokens: ' Once' (+0.02), ' once' (+0.01), ' in' (+0.01), ' the' (+0.01), ' a' (+0.01), ' The' (+0.01)\n",
      "\n",
      "Explanation: storytelling\n",
      "\n",
      "Neuron 3\n",
      "<PROMPT>Given 4x is less than 10,</PROMPT>\n",
      "Most increased tokens: ' 4' (+0.11), ' 10' (+0.04), ' 40' (+0.02), ' 2' (+0.01)\n",
      "\n",
      "<PROMPT>For some reason</PROMPT>\n",
      "Most increased tokens: ' one' (+0.14), ' 1' (+0.01), ' fr' (+0.01)\n",
      "\n",
      "<PROMPT>insurance does not cover claims for accounts with</PROMPT>\n",
      "Most increased tokens: ' one' (+0.1), ' more' (+0.02), ' 10' (+0.01)\n",
      "\n",
      "Explanation: numbers\n",
      "\n",
      "Neuron 4\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.05)\n",
      "\n",
      "<PROMPT>I like to eat</PROMPT>\n",
      "Most increased tokens: ' fro' (+0.14), ' fruit' (+0.13), ' oranges' (+0.11), ' bananas' (+0.1), ' strawberries' (+0.03)\n",
      "\n",
      "Explanation:\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import copy\n",
    "\n",
    "@dataclass\n",
    "class ExplainerInterventionExample:\n",
    "    prompt: str\n",
    "    top_tokens: list[str]\n",
    "    top_p_increases: list[float]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.prompt = self.prompt.replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "    def text(self) -> str:\n",
    "        tokens_str = \", \".join(f\"'{tok}' (+{round(p, 3)})\" for tok, p in zip(self.top_tokens, self.top_p_increases))\n",
    "        return f\"<PROMPT>{self.prompt}</PROMPT>\\nMost increased tokens: {tokens_str}\"\n",
    "    \n",
    "@dataclass\n",
    "class ExplainerNeuronFormatter:\n",
    "    intervention_examples: list[ExplainerInterventionExample]\n",
    "    explanation: str | None = None\n",
    "\n",
    "    def text(self) -> str:\n",
    "        text = \"\\n\\n\".join(example.text() for example in self.intervention_examples)\n",
    "        text += \"\\n\\nExplanation:\"\n",
    "        if self.explanation is not None:\n",
    "            text += \" \" + self.explanation\n",
    "        return text\n",
    "\n",
    "\n",
    "def get_explainer_prompt(neuron_prompter: ExplainerNeuronFormatter, few_shot_examples: list[ExplainerNeuronFormatter] | None = None) -> str:\n",
    "    prompt = \"We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\\n\\n\" \\\n",
    "        \"For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\\n\\n\" \\\n",
    "        \"The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\\n\\n\"\n",
    "    \n",
    "    i = 1\n",
    "    for few_shot_example in few_shot_examples or []:\n",
    "        assert few_shot_example.explanation is not None\n",
    "        prompt += f\"Neuron {i}\\n\" + few_shot_example.text() + \"\\n\\n\"\n",
    "        i += 1\n",
    "\n",
    "    prompt += f\"Neuron {i}\\n\"\n",
    "    prompt += neuron_prompter.text()\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "fs_examples = [\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"My favorite food is\",\n",
    "                top_tokens=[\" oranges\", \" bananas\", \" apples\"],\n",
    "                top_p_increases=[0.81, 0.09, 0.02]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Whenever I would see\",\n",
    "                top_tokens=[\" fruit\", \" a\", \" apples\", \" red\"],\n",
    "                top_p_increases=[0.09, 0.06, 0.06, 0.05]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"I like to eat\",\n",
    "                top_tokens=[\" fro\", \" fruit\", \" oranges\", \" bananas\", \" strawberries\"],\n",
    "                top_p_increases=[0.14, 0.13, 0.11, 0.10, 0.03]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"fruits\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Once\",\n",
    "                top_tokens=[\" upon\", \" in\", \" a\", \" long\"],\n",
    "                top_p_increases=[0.22, 0.2, 0.05, 0.04]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Ryan Quarles\\\\n\\\\nRyan Francis Quarles (born October 20, 1983)\",\n",
    "                top_tokens=[\" once\", \" happily\", \" for\"],\n",
    "                top_p_increases=[0.03, 0.31, 0.01]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"MSI Going Full Throttle @ CeBIT\",\n",
    "                top_tokens=[\" Once\", \" once\", \" in\", \" the\", \" a\", \" The\"],\n",
    "                top_p_increases=[0.02, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "            ),\n",
    "        ],\n",
    "        explanation=\"storytelling\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Given 4x is less than 10,\",\n",
    "                top_tokens=[\" 4\", \" 10\", \" 40\", \" 2\"],\n",
    "                top_p_increases=[0.11, 0.04, 0.02, 0.01]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"For some reason\",\n",
    "                top_tokens=[\" one\", \" 1\", \" fr\"],\n",
    "                top_p_increases=[0.14, 0.01, 0.01]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"insurance does not cover claims for accounts with\",\n",
    "                top_tokens=[\" one\", \" more\", \" 10\"],\n",
    "                top_p_increases=[0.10, 0.02, 0.01]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"numbers\"\n",
    "    )\n",
    "]\n",
    "\n",
    "neuron_prompter = copy.deepcopy(fs_examples[0])\n",
    "neuron_prompter.explanation = None\n",
    "print(get_explainer_prompt(neuron_prompter, fs_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT> oranges\n",
      "\n",
      "Explanation: ateg\n",
      "<PROMPT>From west to east, the westmost of the seven</PROMPT>WAY\n",
      "\n",
      "Explanation: numbers\n",
      "<PROMPT>Given 4x is less than 10,</PROMPT> 4\n",
      "\n",
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT>\n"
     ]
    }
   ],
   "source": [
    "def get_scorer_simplicity_prompt(explanation):\n",
    "    prefix = \"Explanation\\n\\n\"\n",
    "    return f\"{prefix}{explanation}{scorer_tokenizer.eos_token}\", prefix\n",
    "\n",
    "def get_scorer_predictiveness_prompt(prompt, explanation, few_shot_prompts=None, few_shot_explanations=None, few_shot_tokens=None):\n",
    "    if few_shot_explanations is not None:\n",
    "        assert few_shot_tokens is not None and few_shot_prompts is not None\n",
    "        assert len(few_shot_explanations) == len(few_shot_tokens) == len(few_shot_prompts)\n",
    "        few_shot_prompt = \"\\n\\n\".join(get_scorer_predictiveness_prompt(pr, expl) + token for pr, expl, token in zip(few_shot_prompts, few_shot_explanations, few_shot_tokens)) + \"\\n\\n\"\n",
    "    else:\n",
    "        few_shot_prompt = \"\"\n",
    "    return few_shot_prompt + f\"Explanation: {explanation}\\n<PROMPT>{prompt}</PROMPT>\"\n",
    "\n",
    "few_shot_prompts = [\"My favorite food is\", \"From west to east, the westmost of the seven\", \"Given 4x is less than 10,\"]\n",
    "few_shot_explanations = [\"fruits and vegetables\", \"ateg\", \"numbers\"]\n",
    "few_shot_tokens = [\" oranges\", \"WAY\", \" 4\"]\n",
    "print(get_scorer_predictiveness_prompt(few_shot_prompts[0], few_shot_explanations[0], few_shot_prompts, few_shot_explanations, few_shot_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def intervene(module, input, output, intervention_strength=10.0, position=-1, feat=None):\n",
    "    hiddens = output[0]  # the later elements of the tuple are the key value cache\n",
    "    hiddens[:, position, :] += intervention_strength * feat.to(hiddens.device)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_layers = subject.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intervention_tokens = 5\n",
    "scorer_intervention_strengths = [0, 10, 32, 100, 320, 1000]\n",
    "explainer_intervention_strength = 32\n",
    "\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=\"google/gemma-scope-9b-pt-res\",\n",
    "    filename=f\"layer_{feat_layer}/width_131k/average_l0_51/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(subject_device) for k, v in params.items()}\n",
    "\n",
    "\n",
    "def get_encoder_decoder_weights(feat_idx, device, random_resid_direction):\n",
    "    encoder_feat = pt_params[\"W_enc\"][feat_idx, :]\n",
    "    decoder_feat = pt_params[\"W_dec\"][feat_idx, :]\n",
    "    if random_resid_direction:\n",
    "        decoder_feat = torch.randn_like(decoder_feat)\n",
    "    return encoder_feat, decoder_feat\n",
    "\n",
    "\n",
    "def garbage_collect():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "        print(\"CUDA garbage collection performed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert subject_tokenizer.get_vocab() == scorer_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 10.49 seconds\n",
      "[' glass', ' windows', ' shop', ' door', ' side']\n",
      "[0.007918842136859894, 0.0029396452009677887, 0.000982820987701416, 0.0006711115129292011, 0.0006391257047653198]\n",
      "[' degrees', '8', '9', '2', '6']\n",
      "[1.1867938155774027e-05, 6.884278263896704e-06, 6.822760042268783e-06, 6.046495400369167e-06, 5.583569873124361e-06]\n",
      "['“', 'The', 'A', '\"', 'On']\n",
      "[0.005751661956310272, 0.004830658435821533, 0.0012094564735889435, 0.0006070331437513232, 0.0004717400297522545]\n",
      "[' \"', \" '\", '\"', ' E', ' “']\n",
      "[0.018843382596969604, 0.00157957524061203, 0.0013330169022083282, 0.0009814589284360409, 0.0006831996142864227]\n",
      "[' have', ' say', ' mention', ' \"', ' LOOK']\n",
      "[0.01625191420316696, 0.00334613467566669, 0.0020623994059860706, 0.0009762971894815564, 0.0008321376517415047]\n",
      "Counter({'quotes': 3, 'quotation marks': 1, 'symbols': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.37s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.37s/it]\n",
      "1it [01:33, 93.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 78.73 seconds\n",
      "normalized_predictiveness_score=-1.1835374450683591\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 8.10 seconds\n",
      "[' the', ' an', ' a', ' another', ' ']\n",
      "[0.004625275731086731, 0.0022381246089935303, 0.0012402534484863281, 0.0008356817997992039, 0.00019913632422685623]\n",
      "['1', '2', ' ', '5', '6']\n",
      "[2.7468049665912986e-06, 1.1346000974299386e-06, 3.088625817326829e-07, 2.910569492087234e-07, 2.079577825497836e-07]\n",
      "[' an', ' the', ' clear', ' either', ' any']\n",
      "[0.020979493856430054, 0.0003308332525193691, 0.00026065949350595474, 0.00018377765081822872, 0.00017113890498876572]\n",
      "[' led', ' tested', ' put', ' kept', ' made']\n",
      "[0.0008836984634399414, 0.0007538255304098129, 0.0007409974932670593, 0.0006638877093791962, 0.0005448833107948303]\n",
      "[' in', ' for', ' against', ' on', ' and']\n",
      "[0.008508801460266113, 0.0022646524012088776, 0.0021819742396473885, 0.0011248812079429626, 0.0010835528373718262]\n",
      "Counter({'numbers': 5})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]\n",
      "2it [02:07, 58.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 26.26 seconds\n",
      "normalized_predictiveness_score=-1.1469223976135254\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 9.33 seconds\n",
      "[' the', ' Canonical', ' Can', ' ', ' CAN']\n",
      "[0.019162297248840332, 0.018479973077774048, 0.005154597572982311, 0.0035864152014255524, 0.0027160393074154854]\n",
      "[' relevant', ' means', ' official', ' interested', ' competent']\n",
      "[0.005846090614795685, 0.005589604377746582, 0.00272214412689209, 0.0020774826407432556, 0.0019824784249067307]\n",
      "[' the', ' that', ' last', ' they', ' on']\n",
      "[0.003691956400871277, 0.003122478723526001, 0.001771455630660057, 0.0010092006996273994, 0.001000954769551754]\n",
      "[' on', ' outside', ' through', ' before', ' after']\n",
      "[0.0066987499594688416, 0.0026769600808620453, 0.002449234016239643, 0.0008801314979791641, 0.0008492367342114449]\n",
      "[' rights', ' right', ' discrimination', ' issues', ' detention']\n",
      "[0.0014113187789916992, 0.00037645664997398853, 0.000369891757145524, 0.00010785937774926424, 8.752490975894034e-05]\n",
      "Counter({'legal': 1, 'legal documents': 1, 'a noun, often a proper noun': 1, 'legal text': 1, 'words that are often used in law': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]\n",
      "3it [04:29, 96.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 131.65 seconds\n",
      "normalized_predictiveness_score=-0.32393417358398435\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 9.83 seconds\n",
      "[' did', ' made', ' created', ' finished', ' got']\n",
      "[0.002987705171108246, 0.0021089166402816772, 0.0013878047466278076, 9.005784522742033e-05, 8.70607327669859e-05]\n",
      "[' very', ' nice', ' neat', ' cool', ' great']\n",
      "[0.010700983926653862, 0.007432856597006321, 0.004208534490317106, 0.004178110975772142, 0.002053816569969058]\n",
      "[' important', ' exciting', ' memorable', ' special', ' adventurous']\n",
      "[0.014849811792373657, 0.011626994237303734, 0.009479421190917492, 0.007749274373054504, 0.00735454261302948]\n",
      "[' most', ' biggest', ' big', ' event', ' fights']\n",
      "[0.006460733711719513, 0.004815317690372467, 0.004628919064998627, 0.001966264098882675, 0.0017177388072013855]\n",
      "['8', '9', '7', '4', '...']\n",
      "[0.0005819275975227356, 0.0005178079009056091, 0.00015772134065628052, 3.2782554626464844e-06, 1.360458554700017e-07]\n",
      "Counter({'sentiment': 1, 'adjectives': 1, 'a noun, followed by the corresponding adjective': 1, 'past tense': 1, 'words that are positive': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.38s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.37s/it]\n",
      "4it [06:51, 114.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 131.58 seconds\n",
      "normalized_predictiveness_score=-1.237775173187256\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 8.87 seconds\n",
      "[' been', ' come', ' not', ' certainly', ' taken']\n",
      "[0.005828842520713806, 0.0024400316178798676, 0.0017267465591430664, 0.0004254784435033798, 0.0003960728645324707]\n",
      "[' invaded', ' had', ' imposed', ' intervened', ' Embassy']\n",
      "[0.004554763436317444, 0.0028827209025621414, 0.0017738398164510727, 0.0015324330888688564, 0.0013124910183250904]\n",
      "[' from', ' at', ' nor', ' fro', '\\n']\n",
      "[0.02262893319129944, 4.060578066855669e-05, 2.462854899931699e-05, 2.3687243810854852e-05, 1.7537677194923162e-05]\n",
      "[' of', ' men', ' Read', ' women', ' singles']\n",
      "[0.003221750259399414, 0.00229780375957489, 0.0010656416416168213, 0.0007863305509090424, 0.0005323849618434906]\n",
      "[' on', ' after', ' into', ' to', ' over']\n",
      "[0.0038809701800346375, 0.0027465522289276123, 0.002558339387178421, 0.0024374723434448242, 0.0005342736840248108]\n",
      "Counter({'political': 1, 'none': 1, 'politicians, government, politics': 1, 'past tense': 1, 'politics': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.37s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "5it [09:11, 123.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 131.66 seconds\n",
      "normalized_predictiveness_score=-0.8909709739685059\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 8.28 seconds\n",
      "['7', '4', '5', '3', '8']\n",
      "[0.0010830536484718323, 0.000489942729473114, 0.0004773437976837158, 0.0003250911831855774, 0.0002501755952835083]\n",
      "[',', '/', ' Jerry', '.', 'Jerry']\n",
      "[0.005631685256958008, 0.0052846819162368774, 0.0021593626588582993, 0.0021180715411901474, 0.0012285616248846054]\n",
      "['.', ' on', ' at', ' Feb', ' Sept']\n",
      "[0.019575044512748718, 0.005126446485519409, 0.0025830641388893127, 0.0010011615231633186, 0.0006754865171387792]\n",
      "['Appel', '.', ' Appell', ' Karel', ' Cornel']\n",
      "[0.0005667319055646658, 0.00018899468705058098, 0.0001870493870228529, 0.00017209292855113745, 0.00015883834566920996]\n",
      "[' a', ' on', ' probably', ' working', ' also']\n",
      "[0.003400757908821106, 0.0012211054563522339, 0.0007490422576665878, 0.0006103911437094212, 0.0005946112796664238]\n",
      "Counter({'numbers': 2, 'dates': 1, 'dates, numbers': 1, 'dates and numbers': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "6it [11:05, 120.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 105.38 seconds\n",
      "normalized_predictiveness_score=-1.0986333847045897\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 11.77 seconds\n",
      "[' in', ' to', ' for', ' so', ' (']\n",
      "[0.003654271364212036, 0.0030960291624069214, 0.0013840124011039734, 0.00028721895068883896, 0.00025981664657592773]\n",
      "[' in', ' top', ' timely', ' relevant', ' hot']\n",
      "[0.006657872349023819, 0.002183586359024048, 0.001974262297153473, 0.0017239898443222046, 0.0009134896099567413]\n",
      "[' the', ' being', ' running', ' not', ' keeping']\n",
      "[0.007752776145935059, 0.0037232227623462677, 0.0005478765815496445, 0.0004093702882528305, 0.00037085823714733124]\n",
      "[' singing', ' talent', ' way', ' gift', ' knack']\n",
      "[0.005230717360973358, 0.0038839876651763916, 0.0017700418829917908, 0.0017595961689949036, 0.001476682722568512]\n",
      "[' s', ' ratings', '€™', ' cable', ' premium']\n",
      "[1.0356961865909398e-06, 9.642499207984656e-07, 8.060587788349949e-07, 6.921766271261731e-07, 4.782202722708462e-07]\n",
      "Counter({'adjectives': 3, 'adjectives describing things (such as \"magic power\", \"new mystery novel\", \"pretty dress\", \"': 1, 'words are more likely to occur when the prompt is about TV': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.43s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n",
      "7it [12:36, 110.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring took 79.31 seconds\n",
      "normalized_predictiveness_score=-0.3431140899658203\n",
      "\n",
      "\n",
      "CUDA garbage collection performed.\n",
      "Loading autoencoder...done\n",
      "Getting explanations...\n",
      "Explainer took 10.47 seconds\n",
      "['4', '1', '2', '.', ' Δ']\n",
      "[0.002171456813812256, 0.00010591931641101837, 6.465800106525421e-05, 1.7496466170996428e-05, 6.647926056757569e-06]\n",
      "['playing', 'player', 'Playing', 'plays', 'p']\n",
      "[0.013190865516662598, 0.00018440000712871552, 0.0001676729880273342, 2.886043512262404e-05, 1.995847560465336e-05]\n",
      "[' (', ',', ' of', 'berg', 'eaux']\n",
      "[0.006079591810703278, 0.004985928535461426, 0.001190527225844562, 0.0006750426255166531, 0.0002493110951036215]\n",
      "[' childhood', ' youth', ' infancy', ' age', ' tender']\n",
      "[0.01592208445072174, 0.00627363845705986, 0.005018085241317749, 0.00048429612070322037, 0.0003074272535741329]\n",
      "[' because', ' (', '.\"', ' the', '-']\n",
      "[0.0009946245700120926, 0.00031023938208818436, 0.0002858508378267288, 0.00020172609947621822, 0.00019023241475224495]\n",
      "Counter({'numbers': 1, 'references to numbers': 1, 'numbers, parentheses': 1, 'Numbers in text (such as dates and times)': 1, 'symbols': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.40s/it]\n",
      "100%|██████████| 6/6 [00:26<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from itertools import product, islice\n",
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "random_resid_direction = False  # this is a random baseline\n",
    "save_path = f\"counterfactual_results/neg_{subject_name.split('/')[-1]}_{feat_layer}layer_{n_feats}feats{'_random_dir' if random_resid_direction else ''}.json\"\n",
    "all_results = []\n",
    "n_explanations = 5\n",
    "n_scorer_texts = 10\n",
    "n_explainer_texts = 7\n",
    "\n",
    "\n",
    "for iter, record in enumerate(tqdm(islice(loader, 10))):\n",
    "    garbage_collect()\n",
    "    \n",
    "    feat_idx = record.feature.feature_index\n",
    "    print(\"Loading autoencoder...\", end=\"\")\n",
    "    encoder_feat, decoder_feat = get_encoder_decoder_weights(feat_idx, subject_device, random_resid_direction)\n",
    "\n",
    "    ### Find examples where the feature activates\n",
    "    # Remove any hooks\n",
    "    for l in range(len(subject_layers)):\n",
    "        subject_layers[l]._forward_hooks.clear()\n",
    "    print(\"done\")\n",
    "\n",
    "    random.shuffle(record.train)\n",
    "    scorer_texts = [subject_tokenizer.decode(e.tokens) for e in record.train[:n_scorer_texts]]\n",
    "    explainer_texts = [subject_tokenizer.decode(e.tokens) for e in record.train[:n_explainer_texts]]\n",
    "    \n",
    "    # get explanation\n",
    "    print(\"Getting explanations...\")\n",
    "    def get_subject_logits(text, layer, intervention_strength=0.0, position=-1, feat=None):\n",
    "        for l in range(len(subject_layers)):\n",
    "            subject_layers[l]._forward_hooks.clear()\n",
    "        subject_layers[layer].register_forward_hook(partial(intervene, intervention_strength=intervention_strength, position=-1, feat=feat))\n",
    "\n",
    "        inputs = subject_tokenizer(text, return_tensors=\"pt\", add_special_tokens=True).to(subject_device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = subject(**inputs)\n",
    "\n",
    "        return outputs.logits[0, -1, :]\n",
    "\n",
    "    explainer_time = time.time()\n",
    "    intervention_examples = []\n",
    "    for text in explainer_texts:\n",
    "        clean_logits = get_subject_logits(text, feat_layer, intervention_strength=0.0, feat=decoder_feat)\n",
    "        intervened_logits = get_subject_logits(text, feat_layer, intervention_strength=explainer_intervention_strength, feat=decoder_feat)\n",
    "        top_probs = (intervened_logits.softmax(dim=-1) - clean_logits.softmax(dim=-1)).topk(n_intervention_tokens)\n",
    "        \n",
    "        top_tokens = [subject_tokenizer.decode(i) for i in top_probs.indices]\n",
    "        top_p_increases = top_probs.values.tolist()\n",
    "        intervention_examples.append(\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=text,\n",
    "                top_tokens=top_tokens,\n",
    "                top_p_increases=top_p_increases\n",
    "            )\n",
    "        )\n",
    "\n",
    "    neuron_prompter = ExplainerNeuronFormatter(\n",
    "        intervention_examples=intervention_examples\n",
    "    )\n",
    "\n",
    "    # TODO: improve the few-shot examples\n",
    "    explainer_prompt = get_explainer_prompt(neuron_prompter, fs_examples)\n",
    "    explainer_input_ids = explainer_tokenizer(explainer_prompt, return_tensors=\"pt\").input_ids.to(explainer_device)\n",
    "    with torch.inference_mode():\n",
    "        samples = explainer.generate(\n",
    "            explainer_input_ids,\n",
    "            max_new_tokens=20,\n",
    "            eos_token_id=explainer_tokenizer.encode(\"\\n\")[-1],\n",
    "            num_return_sequences=n_explanations,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "        )[:, explainer_input_ids.shape[1]:]\n",
    "    explanations = Counter([explainer_tokenizer.decode(sample).split(\"\\n\")[0].strip() for sample in samples])\n",
    "    explainer_time = time.time() - explainer_time\n",
    "    print(f\"Explainer took {explainer_time:.2f} seconds\")\n",
    "\n",
    "    for ie in intervention_examples:\n",
    "        print(ie.top_tokens)\n",
    "        print(ie.top_p_increases)\n",
    "    print(explanations)\n",
    "\n",
    "    scoring_time = time.time()\n",
    "    predictiveness_score_by_explanation = dict()\n",
    "    normalized_predictiveness_score_by_explanation = dict()\n",
    "    all_pred_scores = []\n",
    "    scoring_interventions = dict()\n",
    "    for explanation in explanations:\n",
    "        expl_predictiveness_scores = []\n",
    "        scoring_interventions[explanation] = dict()\n",
    "        for scorer_intervention_strength in tqdm(scorer_intervention_strengths):\n",
    "            \n",
    "            current_pred_scores = []\n",
    "            max_intervened_prob = 0.0\n",
    "            scoring_interventions[explanation][scorer_intervention_strength] = []\n",
    "            for text in scorer_texts:\n",
    "                \n",
    "                intervened_probs = get_subject_logits(text, feat_layer, intervention_strength=scorer_intervention_strength, feat=decoder_feat).softmax(dim=-1).to(scorer_device)\n",
    "\n",
    "                # get the explanation predictiveness\n",
    "                scorer_predictiveness_prompt = get_scorer_predictiveness_prompt(text, explanation, few_shot_prompts, few_shot_explanations, few_shot_tokens)\n",
    "                scorer_input_ids = scorer_tokenizer(scorer_predictiveness_prompt, return_tensors=\"pt\").input_ids.to(scorer_device)\n",
    "                with torch.inference_mode():\n",
    "                    scorer_logits = scorer(scorer_input_ids).logits[0, -1, :]\n",
    "                    scorer_logp = scorer_logits.log_softmax(dim=-1)\n",
    "                \n",
    "                current_pred_scores.append((intervened_probs * scorer_logp).sum())\n",
    "\n",
    "                topk = intervened_probs.topk(n_intervention_tokens).indices\n",
    "                top_tokens = [subject_tokenizer.decode(i) for i in topk]\n",
    "                scoring_interventions[explanation][scorer_intervention_strength].append({\n",
    "                    \"prompt\": text,\n",
    "                    \"top_tokens\": top_tokens,\n",
    "                    \"top_token_probs\": intervened_probs[topk].tolist()\n",
    "                })\n",
    "\n",
    "            expl_predictiveness_scores.append(torch.tensor(current_pred_scores).mean().item())\n",
    "            all_pred_scores.extend(current_pred_scores * explanations[explanation])  # as if we did the inference on the scorer multiple times\n",
    "    \n",
    "        assert scorer_intervention_strengths[0] == 0\n",
    "        null_predictiveness_score = expl_predictiveness_scores[0]\n",
    "        normalized_predictiveness_scores = [score - null_predictiveness_score for score in expl_predictiveness_scores[1:]]\n",
    "        normalized_predictiveness_score = sum(normalized_predictiveness_scores) / len(normalized_predictiveness_scores)\n",
    "        predictiveness_score = normalized_predictiveness_score + null_predictiveness_score\n",
    "        \n",
    "        predictiveness_score_by_explanation[explanation] = predictiveness_score\n",
    "        normalized_predictiveness_score_by_explanation[explanation] = normalized_predictiveness_score\n",
    "    \n",
    "    # note that this computes stderr over explanations, pile samples, *and* intervention strengths (which is kind of weird)\n",
    "    pred_score_stderr = torch.std(torch.tensor(all_pred_scores)).item() / len(all_pred_scores) ** 0.5\n",
    "    pred_score = torch.mean(torch.tensor(all_pred_scores)).item()\n",
    "    normalized_predictiveness_score = sum([normalized_predictiveness_score_by_explanation[explanation] * count for explanation, count in explanations.items()]) / sum(explanations.values())\n",
    "\n",
    "    scoring_time = time.time() - scoring_time\n",
    "    print(f\"Scoring took {scoring_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"{normalized_predictiveness_score=}\")\n",
    "    print()\n",
    "    print()\n",
    "    all_results.append({\n",
    "        \"feat_idx\": feat_idx,\n",
    "        \"feat_layer\": feat_layer,\n",
    "        \"explanations\": dict(explanations),\n",
    "        \"predictiveness_score\": pred_score,\n",
    "        \"normalized_predictiveness_score\": normalized_predictiveness_score,\n",
    "        \"predictiveness_score_stderr\": pred_score_stderr,\n",
    "        \"max_predictiveness_score\": max(predictiveness_score_by_explanation.values()),\n",
    "        \"max_normalized_predictiveness_score\": max(normalized_predictiveness_score_by_explanation.values()),\n",
    "        \"explainer_prompts\": [example.prompt for example in intervention_examples],\n",
    "        \"explainer_top_tokens\": [example.top_tokens for example in intervention_examples],\n",
    "        \"explainer_top_p_increases\": [example.top_p_increases for example in intervention_examples],\n",
    "        \"scorer_intervention_strengths\": scorer_intervention_strengths,\n",
    "        \"explainer_intervention_strength\": explainer_intervention_strength,\n",
    "        \"scorer_texts\": scorer_texts,\n",
    "        \"explainer_texts\": explainer_texts,\n",
    "        \"predictiveness_score_by_explanation\": predictiveness_score_by_explanation,\n",
    "        \"normalized_predictiveness_score_by_explanation\": normalized_predictiveness_score_by_explanation,\n",
    "        \"scoring_interventions\": scoring_interventions\n",
    "    })\n",
    "    if (iter - 1) % 10 == 0:\n",
    "        all_df = pd.DataFrame(all_results)\n",
    "        all_df = all_df.sort_values(\"predictiveness_score\", ascending=False)\n",
    "        all_df.to_json(save_path)\n",
    "all_df = pd.DataFrame(all_results)\n",
    "all_df = all_df.sort_values(\"predictiveness_score\", ascending=False)\n",
    "all_df.to_json(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_df = pd.read_json(\"counterfactual_results/gemma-2-9b_32layer_300feats.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/214) \"prepositional phrases (mostly \"in\")\" | layer 32, idx 36\n",
      "\texplanations: {'spatial': 1, 'prepositions': 3, 'prepositional phrases (mostly \"in\")': 1}\n",
      "\tnormalized predictiveness score: 1.3 ± 0.1\n",
      "\tmax normalized predictiveness score: 1.7 (expl=prepositional phrases (mostly \"in\"))\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT>123»BEIRUT—Syrian rebels clashed with regime troops in the narrow stone alleyways around a historic 12th century mosque in the Old City of Aleppo on Thursday, while a government airstrike north of the city killed at least seven people, activists said. The rebels, who have been slowly</PROMPT>\n",
      "\t\tMost increased tokens: ' en' (+0.009), ' surrounding' (+0.008), ' encro' (+0.006), ' taking' (+0.004), ' over' (+0.003)\n",
      "\n",
      "\t<PROMPT><bos> coverage. Though adjustable, each unit easily conceals the 161-square-foot area typically allotted per family.\\nBan, paired with his students from Tokyo, loaded the disassembled parts into a van and headed north to several evacuation centers in late March. Their mission was to demonstrate how the system works and</PROMPT>\n",
      "\t\tMost increased tokens: ' receive' (+0.001), ' distribute' (+0.001), ' gauge' (+0.001), ' invite' (+0.001), ' collect' (+0.001)\n",
      "\n",
      "\t<PROMPT> railroad companies respectively, and of the disposition of their respective incomes, are not and cannot, without further legislation, be secure in their interests in and concerning said respective railroads and corporations, either as mentioned in said acts or otherwise; and\\n'Whereas a due regard to the rights of said several companies respectively, as mentioned in</PROMPT>\n",
      "\t\tMost increased tokens: ' the' (+0.004), ' and' (+0.0), ' their' (+0.0), ' such' (+0.0), ' section' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos>ENSTRATA is a new corporation, looking towards a new future, what are the possibilities of new corporate strategies? The countries of Africa have many poor people trying to survive on less than $1.25 a day. And these countries are rich in minerals and ores. Their tenants should be richer from the rents</PROMPT>\n",
      "\t\tMost increased tokens: ' of' (+0.024), ' in' (+0.004), ' on' (+0.001), ' collected' (+0.001), '/' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos> some of the most impoverished countries have been humbling and serve as a continuous reminder to help those who are less fortunate. So he has taken his own message to heart. Since 1992, Sader has sponsored two children through ChildFund – a girl from Brazil and a boy from Kenya. Both youth are</PROMPT>\n",
      "\t\tMost increased tokens: ' in' (+0.016), ' still' (+0.001), ' close' (+0.001), ' part' (+0.001), ' from' (+0.001)\n",
      "\n",
      "\t<PROMPT><bos> Racetrack for the venue’s summer concert series opener.\\nBy Melody Burri, staff writer\\nFarmington, N.Y.\\nWould-be concert-goers clogged intersections and shoe-horned themselves into parking spots on roadsides, neighboring lots and residents’ yards for miles around the concert site</PROMPT>\n",
      "\t\tMost increased tokens: ' in' (+0.023), ' of' (+0.005), ' at' (+0.004), ' on' (+0.004), ' near' (+0.002)\n",
      "\n",
      "\t<PROMPT> with my daughters to NYC. We had a fantastic time and enjoyed tea at the American Girl Store so much! Even my often-sullen 13-year-old kept grinning and saying \"This is awesome!\" We also visited Chinatown and the Metropolitan Museum and Times Square as well as some gorgeous churches. Good weather</PROMPT>\n",
      "\t\tMost increased tokens: ' in' (+0.009), ' throughout' (+0.002), ' all' (+0.001), ' on' (+0.001), ' during' (+0.001)\n",
      "\n",
      "(2/214) \"\"to\"\" | layer 32, idx 281\n",
      "\texplanations: {'prepositions': 2, 'and/to': 1, 'prepositions and conjunctions': 1, '\"to\"': 1}\n",
      "\tnormalized predictiveness score: 1.0 ± 0.1\n",
      "\tmax normalized predictiveness score: 1.5 (expl=\"to\")\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT><bos> Surnames: Durfee Family Genealogy Forum Henry Durfee returns from dead, Wayne Twp., Ill., 1901\\nPosted by: Elizabeth (ID *****5332)\\nof 889 St. Charles (Kane County, Illinois) Chronicle, Feb. 15, 1</PROMPT>\n",
      "\t\tMost increased tokens: '8' (+0.001), ' to' (+0.0), ' and' (+0.0), ' for' (+0.0), 'to' (+0.0)\n",
      "\n",
      "\t<PROMPT> that may already have your answer.\\nIf you don't find your answer, you can post your question to WebMD Experts and Contributors.\\nFeaturing Experts From\\n| Next Question\\nPosted: | Report This\\nReport Question | Q.\\nWhat increases the risk of getting Multiple Sclerosis MS?\\nRelated Topics</PROMPT>\n",
      "\t\tMost increased tokens: ' to' (+0.01), ' for' (+0.003), ' To' (+0.002), '.' (+0.001), ' and' (+0.001)\n",
      "\n",
      "\t<PROMPT><bos> out of your water once it's added. Many do not have the resources or the knowledge to do so. The only real solution is to stop the archaic practice of water fluoridation in the first place. Fortunately, the Fluoride Action Network has a game plan to END water fluoridation, both in the United</PROMPT>\n",
      "\t\tMost increased tokens: ' States' (+0.001), ' to' (+0.0), ' states' (+0.0), ',' (+0.0), ' and' (+0.0)\n",
      "\n",
      "\t<PROMPT>and $50 is fine for the reasons others have stated already) is that snake owners are on the lookout for free or low cost bunnies for food. It's a terrible problem on Craigslist, so between screening and fees at shelters, you're really saving a bunny's life in several ways. And explaining</PROMPT>\n",
      "\t\tMost increased tokens: ' to' (+0.039), ' so' (+0.001), ' about' (+0.001), ' for' (+0.001), ' how' (+0.0)\n",
      "\n",
      "\t<PROMPT> draft in 2014, but Matt's suggestion to do everything to trade for picks in 2014 will give them the flexibility to work a deal that just might land them a couple (or 3?) high lottery picks.\\nLast edited by Puffer; Tue Dec 18th</PROMPT>\n",
      "\t\tMost increased tokens: ' at' (+0.006), ' to' (+0.001), '.' (+0.001), ' @' (+0.001), ';' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos>\\nI can’t believe even a local journalist dared to ask a democrat a serious question. Wow.\\nActions peak louder than words. It is time to hold politicians accountable for theirs.\\nDownsizeDC\\nWe have to stop paying people to have babies. There are a ton of things that need to change</PROMPT>\n",
      "\t\tMost increased tokens: ' to' (+0.114), ' for' (+0.008), ' so' (+0.002), ' because' (+0.0), ' just' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos> bodies, our sense of self can become unhealthy. It�s not uncommon for people who think poorly of their bodies to have issues in other areas of their lives. Body-image distortion occurs when a person's view of their body is significantly different from reality. This is something I have become very aware that I</PROMPT>\n",
      "\t\tMost increased tokens: ' need' (+0.008), ' needed' (+0.003), ' want' (+0.001), ' can' (+0.001), ' do' (+0.001)\n",
      "\n",
      "(3/214) \"\"more\" (i.e. more of something)\" | layer 32, idx 112\n",
      "\texplanations: {'more': 1, 'adjectives': 1, 'a lot, many, all': 1, '\"more\" (i.e. more of something)': 1, 'words that emphasise': 1}\n",
      "\tnormalized predictiveness score: 0.5 ± 0.2\n",
      "\tmax normalized predictiveness score: 1.0 (expl=\"more\" (i.e. more of something))\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT> development workshops around each show, and free pre-show workshops for students. Students attend evening performances along with our other patrons. They arrive 90 minutes before curtain to participate in a Teaching Artist-led, hands-on workshop related to the production they will see.\\nWe offer a competitive hourly rate and scheduling is</PROMPT>\n",
      "\t\tMost increased tokens: ' very' (+0.013), ' extremely' (+0.002), ' more' (+0.001), ' highly' (+0.001), ' completely' (+0.001)\n",
      "\n",
      "\t<PROMPT><bos>, cheeses, meats, seafood, bakery items, food, and handcrafted garden art. Live music featured. Weekly 9:30 a.m.-2 p.m. Sun, through Oct. 28. Southeast Main Street, across from City Hall, Milwaukie; free admission; www.</PROMPT>\n",
      "\t\tMost increased tokens: 'more' (+0.005), 'm' (+0.003), 'downtown' (+0.002), 'mill' (+0.001), 'c' (+0.001)\n",
      "\n",
      "\t<PROMPT><bos>/alt-text culmination, and less at the means he happened to use to get there. All this put together reveals Randall as an elitist prick who doesn't know what the fuck he's talking about. And yet SOMEHOW he has a huge following of people who think his word is the word of</PROMPT>\n",
      "\t\tMost increased tokens: ' god' (+0.004), ' a' (+0.003), ' the' (+0.002), ' fucking' (+0.002), ' an' (+0.001)\n",
      "\n",
      "\t<PROMPT> Many other local businesses donate products/services including Bagelman of Garden City and Long Island Banana Corp. The race committee, (Race Director Ken Aneser, Kevin Coffey, Bob Freeman, Chris Giarraputo, Mike Kopcak, Charlie Lee, Jim Loughlin, Ian Paisley, Bob Priest, Phil Puccio,</PROMPT>\n",
      "\t\tMost increased tokens: ' Brian' (+0.001), ' &' (+0.001), ' and' (+0.001), ' Joe' (+0.001), ' Michael' (+0.0)\n",
      "\n",
      "\t<PROMPT>8 PM Chris Borland missed most of Wisconsin’s Oct. 19 win over Illinois after tweaking a hamstring Older Posts Advertise With Ustampabay.com\\nXpress, the Coolest Section of the St. Petersburg Times, is the home for features, news and views of interest to young readers. Most of</PROMPT>\n",
      "\t\tMost increased tokens: ' our' (+0.008), ' all' (+0.007), ' what' (+0.002), ' you' (+0.0), ' today' (+0.0)\n",
      "\n",
      "\t<PROMPT>pm The Average Dyke Band will have you on your feet and dancing to old school funk, R &B, modern and more. All are welcome. The event is $15 at the door $10 with student ID. That’s Saturday March 8th at La Pena Cultural Center 3105</PROMPT>\n",
      "\t\tMost increased tokens: ' Telegraph' (+0.0), ' San' (+0.0), ' De' (+0.0), ' Broadway' (+0.0), 'Shat' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos> Its members are diverse in age, race, sector, geographic focus, and more. Few even knew each other before being inducted as Fellows. The few exceptions were those who knew each other from being on opposite ends of pitched battles over neighborhood projects, or funding, or politics. Now, they know and trust each other</PROMPT>\n",
      "\t\tMost increased tokens: ' more' (+0.012), ' enough' (+0.004), ' better' (+0.003), ' so' (+0.002), ' far' (+0.001)\n",
      "\n",
      "(4/214) \"solo, alone\" | layer 32, idx 102\n",
      "\texplanations: {'solo': 2, 'solo, alone': 1, 'solitary nouns': 1, 'words that start with \"s\"': 1}\n",
      "\tnormalized predictiveness score: -0.1 ± 0.1\n",
      "\tmax normalized predictiveness score: 0.7 (expl=solo, alone)\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT> Three: anatman (“not-self”) anitya (“impermanence”) and pratitya-samutpada (“interconnectedness”).\\nToward this end, I offer the following abbreviated science sutra, which this book attempts to flesh out: Not-self, impermanence and interconnectedness are built into the</PROMPT>\n",
      "\t\tMost increased tokens: ' very' (+0.003), ' fundamental' (+0.002), ' basic' (+0.001), ' foundations' (+0.001), ' structure' (+0.001)\n",
      "\n",
      "\t<PROMPT> 4.5), the treatment regimen as recommended for lamotrigine with concurrent valproate, should be used.\\n* Dose may be increased to 400 mg/day as needed Table 5: Adults aged 18 years and above - adjustment of lamotrigine daily dosing following the</PROMPT>\n",
      "\t\tMost increased tokens: ' first' (+0.003), ' initial' (+0.003), ' initiation' (+0.002), ' single' (+0.001), ' individual' (+0.001)\n",
      "\n",
      "\t<PROMPT> army. Isolationists even to their own kind, and each the equal in battle of a gross of trained Orcish Axeblades, despite using only the weapons afforded them by nature in the case of the Green and Horned Trolls, they are treated as chance-met royalty and welcome guests by the Red Eyes.</PROMPT>\n",
      "\t\tMost increased tokens: ' A' (+0.001), ' As' (+0.001), ' Each' (+0.0), ' So' (+0.0), ' Even' (+0.0)\n",
      "\n",
      "\t<PROMPT> concepts. A visible writing space is instrumental in facilitating structured lessons and clear communication.Should you get a double-sided chalkboard? That depends on you room space and layout. Hertz Furniture&apos;s wide selection of chalkboards includes wall-mounted models as well as portable units. Give your lessons the jump start they need</PROMPT>\n",
      "\t\tMost increased tokens: ' with' (+0.002), ' when' (+0.001), ' for' (+0.0), ' thanks' (+0.0), ' as' (+0.0)\n",
      "\n",
      "\t<PROMPT> aka \"Soldier\" (Ciaran Hinds) and Toy aka \"Poor Man\" (David Dencik). Working with Peter (Benedict Cumberbatch) a conflicted younger member of the service and Ricki (Tom Hardy) a rogue agent who has information of his own Smiley slowly uncovers the muddled truth—occasionally breaking</PROMPT>\n",
      "\t\tMost increased tokens: ' his' (+0.009), ' out' (+0.003), ' away' (+0.001), ' rules' (+0.001), ' off' (+0.001)\n",
      "\n",
      "\t<PROMPT>iously singing the electrco-soul centered number. We've already heard new tracks \"What A Shame\" and \"why_ya_why.\" And now with another sample in \"You Naked\" from the upcoming album, it looks like we're going to get the mad scientist back bringing some the boom in his</PROMPT>\n",
      "\t\tMost increased tokens: ' solo' (+0.034), ' own' (+0.012), ' first' (+0.002), ' debut' (+0.001), ' one' (+0.001)\n",
      "\n",
      "\t<PROMPT>\\nI have to stay out of the sun. I moved to Florida because I love the beach. Now I can't go to the beach, except after sunset. I don't go out in the boat. I can't scuba dive. My husband is a diver too, but now he goes with friends</PROMPT>\n",
      "\t\tMost increased tokens: ' alone' (+0.003), ' by' (+0.001), ' who' (+0.001), ' only' (+0.001), ' solo' (+0.001)\n",
      "\n",
      "(5/214) \"lose or lost\" | layer 32, idx 204\n",
      "\texplanations: {'losses': 1, 'loss': 1, 'loss, losing': 1, 'lose or lost': 1, 'end of story': 1}\n",
      "\tnormalized predictiveness score: 0.2 ± 0.1\n",
      "\tmax normalized predictiveness score: 0.7 (expl=lose or lost)\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT><bos>, distract!” Ryan finished by emphasizing America’s fascination with the Wisconsin recall. “This is an election that will send shock waves throughout America,” he said. “This is either a momentum maker or momentum breaker. The stakes are as high as they ever could be. Because courage is on the ballot Tuesday,” he</PROMPT>\n",
      "\t\tMost increased tokens: ' concluded' (+0.005), ' finished' (+0.002), ' ended' (+0.001), ' closed' (+0.0), ' imp' (+0.0)\n",
      "\n",
      "\t<PROMPT> (B 37920)\\nDigital records require reliable backup. Your computer is not reliable. Synching them out to Google might seem reasonable reliable, but I've heard horror stories about people having their accounts canceled by the company. Paper records also require reliable backup. It's all fun and</PROMPT>\n",
      "\t\tMost increased tokens: ' good' (+0.002), ' easy' (+0.0), ' well' (+0.0), ' interesting' (+0.0), ' fine' (+0.0)\n",
      "\n",
      "\t<PROMPT> are now in contention to start against Bayern.\\nCity however will be without summer acquisition Martin Demichelis who is yet to play a single minute for his new side.\\nFormer Dortmund star Mario Gotze who has only recently returned from an ankle injury was an unused substitute during the 1-0 victory over Wolfsburg,</PROMPT>\n",
      "\t\tMost increased tokens: ' but' (+0.001), ' leaving' (+0.001), ' losing' (+0.001), ' a' (+0.0), ' the' (+0.0)\n",
      "\n",
      "\t<PROMPT>2012. *Be flexible in my end goal weight. Don't get stuck on the idea of a magic number and feel like a lame loser if I don't succeed. *Have fun *Love my life *Enjoy my family and friends *Be happy -------------------------------------------------------------- I'm DONE</PROMPT>\n",
      "\t\tMost increased tokens: ' losing' (+0.021), ' LOS' (+0.005), ' with' (+0.003), ' L' (+0.001), ' WITH' (+0.001)\n",
      "\n",
      "\t<PROMPT> of a branded drug pays another company to keep the generic – and much cheaper – drugs it produces out of the market.\\nBoth companies have something to gain in such deals, but you will agree with me that they are not necessarily in the interest of the people and of health care.\\nPay-for-delay transactions</PROMPT>\n",
      "\t\tMost increased tokens: ' deprive' (+0.003), ' cost' (+0.002), ' result' (+0.001), ' reduce' (+0.001), ' involve' (+0.001)\n",
      "\n",
      "\t<PROMPT><bos> zoning in building additional schools.\\nSmaller schools districts could benefit by meeting and sharing information with other\\nsmall school districts.\\nKERN COUNTY SCHOOL DISTRICTS\\nThis report is submitted pursuant to California Penal Code 925, to follow up on a\\nBakersfield Californian article of March 25, </PROMPT>\n",
      "\t\tMost increased tokens: '2' (+0.001), '0' (+0.0), '5' (+0.0), '\n",
      "' (+0.0), '<strong>' (+0.0)\n",
      "\n",
      "\t<PROMPT> down [Claire L. Gaudiani]: Over 70% of the faculty members at Connecticut college signed a petition to have her lose her job as president, and she did.” (The New York Times ran a puff piece upon her departure full of praise, including from a Pfizer representative involved in pushing for the benefits</PROMPT>\n",
      "\t\tMost increased tokens: ' loss' (+0.008), ' lost' (+0.004), ' cuts' (+0.001), ' they' (+0.001), ' she' (+0.0)\n",
      "\n",
      "(10/214) \"prepositions\" | layer 32, idx 273\n",
      "\texplanations: {'nature': 1, 'none': 1, 'a noun, followed by the corresponding preposition': 1, 'stop': 1, 'prepositions': 1}\n",
      "\tnormalized predictiveness score: -0.1 ± 0.1\n",
      "\tmax normalized predictiveness score: 0.3 (expl=prepositions)\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT> whether a transmission was successful. To solve this problem, DCF ensures that each frame is acknowledged once the transmission is successfully received. Specifically, there is a provision in DCF where all clients keep silent after a transmission finishes so the receiving station has a chance to send the acknowledgement. This is period is called the Short Inter</PROMPT>\n",
      "\t\tMost increased tokens: '-' (+0.017), 'Frame' (+0.006), 'ruption' (+0.0), 'station' (+0.0), 'mission' (+0.0)\n",
      "\n",
      "\t<PROMPT> must then direct the captain to a certain place where they may disembark. Continuing on foot they must deliver two large cod and a chainsaw to a summer lodge which is located up a steep hill.Choice quotes: \"If that would have been any further I would have chucked my bike down the mountain\", Mallory did not</PROMPT>\n",
      "\t\tMost increased tokens: ' stop' (+0.004), ' want' (+0.003), ' even' (+0.003), ' let' (+0.002), ' hesitate' (+0.002)\n",
      "\n",
      "\t<PROMPT> 411 in White, taking with it phone lines. Hahn said both lanes were closed for some time as crews cleared the debris and lines.She added that the department had received calls concerning trees on power lines, but Georgia Power was working those.The utility company reported 162,000 outages</PROMPT>\n",
      "\t\tMost increased tokens: ' in' (+0.005), ' at' (+0.002), ' due' (+0.002), ' for' (+0.001), ' around' (+0.001)\n",
      "\n",
      "\t<PROMPT> in context and they treated us with easy amiability. Their only mention of the flag was to remark that it was probably a pretty good guard against theft; said with warmth and irony and humour. There were several of these sort of encounters. Later, stopping for side-of-the-road hāngi on the</PROMPT>\n",
      "\t\tMost increased tokens: ' way' (+0.01), ' side' (+0.003), ' beach' (+0.001), ' outskirts' (+0.001), ' roadside' (+0.001)\n",
      "\n",
      "\t<PROMPT> reason I like Shakespearean comedy is because it's FUNNY. It can get stilted at times, but watching an actor nowadays speak the written words (speak them in the right way, anyway) is as hilarious to me as any stand-up. There also exists comedy where the stiltedness of the lines</PROMPT>\n",
      "\t\tMost increased tokens: ' and' (+0.003), ' adds' (+0.001), ' allows' (+0.001), ' actually' (+0.001), ' becomes' (+0.001)\n",
      "\n",
      "\t<PROMPT>. There’s been enough math on this that I don’t think it would enlightening to add the formulas by which I convinced myself. For structure, time is the essential variable, and total time elapsed is clearly shorter if the stop is on the moving walkway. That falls out of plugging the problem into d=rt</PROMPT>\n",
      "\t\tMost increased tokens: ' for' (+0.005), ' and' (+0.004), ' to' (+0.003), ':' (+0.0), ' where' (+0.0)\n",
      "\n",
      "\t<PROMPT><bos> donkeys. Bird-lovers will enjoy a visit to Ain Hamran, where ancient trees and shrubs attract many species of birds throughout the year. The final stop is the Natural Springs of Ain Razat, where you'll find stunning cliff views and more birdlife and flora. Top For More Information\\nOman Ministry of</PROMPT>\n",
      "\t\tMost increased tokens: ' Information' (+0.007), ' Tourism' (+0.004), ' Commerce' (+0.001), ' Foreign' (+0.001), ' Environment' (+0.0)\n",
      "\n",
      "(50/214) \"proper nouns\" | layer 32, idx 140\n",
      "\texplanations: {'numbers': 2, 'proper nouns': 1, 'numbers, names, dates': 1, 'numbers, proper names': 1}\n",
      "\tnormalized predictiveness score: -0.2 ± 0.1\n",
      "\tmax normalized predictiveness score: -0.2 (expl=proper nouns)\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT>25 GHz or faster CPU, Mac OS 10.1 or later, 1GB RAM, 8x or faster CD-ROM drive, VGA monitor supporting 1024 x 768 at millions of colors\\nImprint: Butterworth-Heinemann\\nFundoscopy Made Easy Sujoy</PROMPT>\n",
      "\t\tMost increased tokens: ' K' (+0.007), ' G' (+0.004), ' Dat' (+0.002), ' De' (+0.002), ' Kund' (+0.002)\n",
      "\n",
      "\t<PROMPT>...\\nElectronic Plastics - A Global Market Watch, 2011 - 2016\\nGlobal Market Watch: Primarily supported by product application; Kitchen Machinery, Audiovisual Equipment and Domestic Machinery the Electronic Plastics market is projected to reach at a value of US$20...\\nIndustrial Plastics - A Global</PROMPT>\n",
      "\t\tMost increased tokens: ' Industry' (+0.001), '\n",
      "' (+0.0), ' Outlook' (+0.0), ' Strategic' (+0.0), ' Business' (+0.0)\n",
      "\n",
      "\t<PROMPT> NPR.hide Japan coalition partner cautious on Abe's security agenda\\nJapan's Prime Minister Shinzo Abe (C) inspects an honour guard at the Council of Ministers in central Phnom Penh November 16, 2013. Abe is i By Kiyoshi Takenaka\\nTOKYO (Reuters) -</PROMPT>\n",
      "\t\tMost increased tokens: ' Shin' (+0.004), ' Abe' (+0.004), ' Prime' (+0.004), 'Japan' (+0.002), ' New' (+0.001)\n",
      "\n",
      "\t<PROMPT>5 (Bingham) and Re. 30,892 (Bingham et al.). U.S. Pat. No. 3,758,192 (Bingham) discloses a fabric with a retroreflective layer adhered thereto with adhesive. U.S. Pat. No.</PROMPT>\n",
      "\t\tMost increased tokens: ' Re' (+0.001), '\n",
      "' (+0.001), '\n",
      "\n",
      "' (+0.0), ' $' (+0.0), ' No' (+0.0)\n",
      "\n",
      "\t<PROMPT>CFR › Title 39 › Chapter I › Subchapter J › Part 761 › Section 761.3 39 CFR 761.3 - Scope and effect of book-entry procedure.\\nScope and effect of book-entry procedure.\\nA Reserve Bank as fiscal agent</PROMPT>\n",
      "\t\tMost increased tokens: ' of' (+0.009), ' for' (+0.007), ' or' (+0.003), ' and' (+0.001), ' (' (+0.001)\n",
      "\n",
      "\t<PROMPT> also offering the 3G 16.3 megapixel Samsung Galaxy camera, which can act as a mobile Wi-Fi hotspot for up to five other devices and instantly publish photos straight to Facebook and Instagram. iiNet is selling the Samsung camera for $579 outright or $22 per month when bundled</PROMPT>\n",
      "\t\tMost increased tokens: ' on' (+0.005), ' in' (+0.001), ' up' (+0.0), ' over' (+0.0), '.' (+0.0)\n",
      "\n",
      "\t<PROMPT>10, MINI was faced with a dramatically repressed market and no new product news. Our task was to create a campaign that would drive deep engagement around the strategy that MINI was a feisty way to move through an increasingly serious world. The idea to challenge an icon of seriousness, Porsche, to a race was born.</PROMPT>\n",
      "\t\tMost increased tokens: '\n",
      "\n",
      "' (+0.006), ' Porsche' (+0.002), '\n",
      "' (+0.002), '<eos>' (+0.001), ' ' (+0.001)\n",
      "\n",
      "(100/214) \"discourse particles\" | layer 32, idx 274\n",
      "\texplanations: {'conversation': 1, 'and': 1, 'a small set of words': 1, 'discourse particles': 1, 'words that start with \"a\"': 1}\n",
      "\tnormalized predictiveness score: -0.7 ± 0.1\n",
      "\tmax normalized predictiveness score: -0.5 (expl=discourse particles)\n",
      "\n",
      "\tExample counterfactuals (intervention strength = 32):\n",
      "\t<PROMPT> and Ryan were talking, several plays were shown, including a Chad Hall touchdown run against New Mexico and Jimmy Ollis’ fourth-and-1 touchdown run against TCU.\\nI was legitimately stunned seeing the Falcons on the Worldwide Leader.\\nEarlier this week, I was talking to somebody at Air Force about this and he</PROMPT>\n",
      "\t\tMost increased tokens: ' brought' (+0.003), ' basically' (+0.001), ' didn' (+0.001), ' pointed' (+0.001), ' actually' (+0.001)\n",
      "\n",
      "\t<PROMPT>iuth. When their mining exposes and results in their town filling with poisonous miasma, they decide just stand around and to continue digging instead of simply getting as far from the town and thus the miasma as they can. What's worse, even when the protagonists show up and they reveal that a path out has</PROMPT>\n",
      "\t\tMost increased tokens: ' been' (+0.009), ' actually' (+0.001), ' now' (+0.001), ' indeed' (+0.001), ' in' (+0.001)\n",
      "\n",
      "\t<PROMPT> know how you're going to deal with things until you're actually in the danger zone. Thinking about changing nappies during the wife's pregnancy made me feel icky; post-birth, what's the big fucking deal! Yes, he is a rubbish sleeper and my social activity has been reduced to</PROMPT>\n",
      "\t\tMost increased tokens: ' nothing' (+0.002), ' ' (+0.001), ' going' (+0.001), ' fuck' (+0.001), ' the' (+0.001)\n",
      "\n",
      "\t<PROMPT> old record.\\nAm I calling for a “PC police” or whatever ignorant bullshit term is going to be thrown my way when this gets published? Give me a break. I’m far from perfect, and frankly I’ve never met anyone who isn’t. I love the DIY punk community, I love</PROMPT>\n",
      "\t\tMost increased tokens: ' that' (+0.008), ' it' (+0.004), ' seeing' (+0.003), ' what' (+0.002), ' how' (+0.002)\n",
      "\n",
      "\t<PROMPT>encer array with that works more like a creative musical device than most out there. My inspiration came from the way that most simple \"pattern bank\" software works -- load up a bank of patterns, and arrange a sequence of them to create a song.\\nIt also just serves as a sequencer expander. It allows</PROMPT>\n",
      "\t\tMost increased tokens: ' me' (+0.007), ' up' (+0.001), ' ' (+0.0), ' one' (+0.0), ' to' (+0.0)\n",
      "\n",
      "\t<PROMPT> first published novel - hubris, perhaps. The irony for me is that this used to be my view of things - one of the reasons that I didn't join a writing group earlier was that I was waiting until I had an agent or publisher lined up. It would then have been my job to \"offer\"</PROMPT>\n",
      "\t\tMost increased tokens: ' to' (+0.003), ' something' (+0.003), ' and' (+0.003), ' it' (+0.003), ' things' (+0.002)\n",
      "\n",
      "\t<PROMPT><bos> that's how children are, clueless. Our modern PC loser crew expects sanitized BS to be swallowed whole, and that's what you're all about, since you can't get anything correct. Reply\\njayseeks - Monday, March 25, 2013 - link\\n</PROMPT>\n",
      "\t\tMost increased tokens: 'So' (+0.002), 'That' (+0.002), 'Yeah' (+0.002), 'Well' (+0.001), 'And' (+0.001)\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m all_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_normalized_predictiveness_score\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m)) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m49\u001b[39m, \u001b[38;5;241m99\u001b[39m, \u001b[38;5;241m499\u001b[39m, \u001b[38;5;241m999\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     best_expl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(row\u001b[38;5;241m.\u001b[39mnormalized_predictiveness_score_by_explanation, key\u001b[38;5;241m=\u001b[39mrow\u001b[38;5;241m.\u001b[39mnormalized_predictiveness_score_by_explanation\u001b[38;5;241m.\u001b[39mget)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mbest_expl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m | layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;241m.\u001b[39mfeat_layer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, idx \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow\u001b[38;5;241m.\u001b[39mfeat_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "x = all_df.sort_values(\"max_normalized_predictiveness_score\", ascending=False)\n",
    "for i in list(range(5)) + [9, 49, 99, 499, 999]:\n",
    "\n",
    "    row = x.iloc[i]\n",
    "    best_expl = max(row.normalized_predictiveness_score_by_explanation, key=row.normalized_predictiveness_score_by_explanation.get)\n",
    "    print(f\"({i + 1}/{len(x)}) \\\"{best_expl}\\\" | layer {row.feat_layer}, idx {row.feat_idx}\")\n",
    "    print(f\"\\texplanations: {row.explanations}\")\n",
    "    print(f\"\\tnormalized predictiveness score: {row.normalized_predictiveness_score:.1f} ± {row.predictiveness_score_stderr:.1f}\")\n",
    "    print(f\"\\tmax normalized predictiveness score: {row.max_normalized_predictiveness_score:.1f} (expl={best_expl})\")\n",
    "    print(\"\\n\\tExample counterfactuals (intervention strength = 32):\")\n",
    "    for pr, tts, tpis in zip(row[\"explainer_prompts\"], row[\"explainer_top_tokens\"], row[\"explainer_top_p_increases\"]):\n",
    "        ex = ExplainerInterventionExample(\n",
    "                    prompt=pr,\n",
    "                    top_tokens=tts,\n",
    "                    top_p_increases=tpis\n",
    "                )\n",
    "        print(\"\\t\" + ex.text().replace(\"\\nMost\", \"\\n\\t\\tMost\") + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autointerp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
