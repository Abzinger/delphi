{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject model\n",
    "# load SAEs without attaching them to the model\n",
    "# for now just use the Islam feature and explanation\n",
    "# load a scorer. The prompt should have the input as well this time\n",
    "# (for now) on random pretraining data, evaluate gpt2 with a hook that \n",
    "# adds a multiple of the Islam feature to the appropriate residual stream layer and position\n",
    "# Get the pre- and post-intervention output distributions of gpt2\n",
    "# (TODO: check if all the Islam features just have similar embeddings)\n",
    "# Show this to the scorer and get a score (scorer should be able to have a good prior without being given the clean output distribution)\n",
    "# Also get a simplicity score for the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev_correlation_score</th>\n",
       "      <th>layer</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature0</th>\n",
       "      <td>0.970093</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature19</th>\n",
       "      <td>0.966378</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature0</th>\n",
       "      <td>0.952401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature4</th>\n",
       "      <td>0.952061</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature5</th>\n",
       "      <td>0.949993</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature4</th>\n",
       "      <td>0.941871</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature11</th>\n",
       "      <td>0.930066</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature19</th>\n",
       "      <td>0.918787</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature14</th>\n",
       "      <td>0.906342</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature3</th>\n",
       "      <td>0.897080</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature11</th>\n",
       "      <td>0.883083</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature9</th>\n",
       "      <td>0.868529</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature3</th>\n",
       "      <td>0.810241</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature18</th>\n",
       "      <td>0.805457</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature16</th>\n",
       "      <td>0.782019</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature11</th>\n",
       "      <td>0.779133</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature10</th>\n",
       "      <td>0.772255</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature7</th>\n",
       "      <td>0.764754</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature7</th>\n",
       "      <td>0.712047</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature12</th>\n",
       "      <td>0.711850</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature0</th>\n",
       "      <td>0.698656</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature12</th>\n",
       "      <td>0.678797</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature15</th>\n",
       "      <td>0.668821</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature13</th>\n",
       "      <td>0.668621</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature1</th>\n",
       "      <td>0.662348</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature2</th>\n",
       "      <td>0.659443</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature13</th>\n",
       "      <td>0.649270</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature3</th>\n",
       "      <td>0.645487</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature6</th>\n",
       "      <td>0.643440</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature17</th>\n",
       "      <td>0.627347</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature8</th>\n",
       "      <td>0.583940</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature15</th>\n",
       "      <td>0.556673</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature4</th>\n",
       "      <td>0.470279</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature6</th>\n",
       "      <td>0.447680</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature7</th>\n",
       "      <td>0.390438</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature18</th>\n",
       "      <td>0.378467</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature14</th>\n",
       "      <td>0.316718</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature9</th>\n",
       "      <td>0.272719</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature10</th>\n",
       "      <td>0.228020</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature13</th>\n",
       "      <td>0.167355</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature5</th>\n",
       "      <td>0.095751</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature2</th>\n",
       "      <td>0.023048</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature15</th>\n",
       "      <td>-0.060541</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ev_correlation_score  layer  feature\n",
       ".transformer.h.2_feature0               0.970093      2        0\n",
       ".transformer.h.2_feature19              0.966378      2       19\n",
       ".transformer.h.0_feature0               0.952401      0        0\n",
       ".transformer.h.4_feature4               0.952061      4        4\n",
       ".transformer.h.0_feature5               0.949993      0        5\n",
       ".transformer.h.2_feature4               0.941871      2        4\n",
       ".transformer.h.2_feature11              0.930066      2       11\n",
       ".transformer.h.4_feature19              0.918787      4       19\n",
       ".transformer.h.0_feature14              0.906342      0       14\n",
       ".transformer.h.0_feature3               0.897080      0        3\n",
       ".transformer.h.0_feature11              0.883083      0       11\n",
       ".transformer.h.0_feature9               0.868529      0        9\n",
       ".transformer.h.2_feature3               0.810241      2        3\n",
       ".transformer.h.2_feature18              0.805457      2       18\n",
       ".transformer.h.0_feature16              0.782019      0       16\n",
       ".transformer.h.4_feature11              0.779133      4       11\n",
       ".transformer.h.0_feature10              0.772255      0       10\n",
       ".transformer.h.0_feature7               0.764754      0        7\n",
       ".transformer.h.2_feature7               0.712047      2        7\n",
       ".transformer.h.0_feature12              0.711850      0       12\n",
       ".transformer.h.4_feature0               0.698656      4        0\n",
       ".transformer.h.4_feature12              0.678797      4       12\n",
       ".transformer.h.4_feature15              0.668821      4       15\n",
       ".transformer.h.4_feature13              0.668621      4       13\n",
       ".transformer.h.2_feature1               0.662348      2        1\n",
       ".transformer.h.2_feature2               0.659443      2        2\n",
       ".transformer.h.0_feature13              0.649270      0       13\n",
       ".transformer.h.4_feature3               0.645487      4        3\n",
       ".transformer.h.2_feature6               0.643440      2        6\n",
       ".transformer.h.4_feature17              0.627347      4       17\n",
       ".transformer.h.4_feature8               0.583940      4        8\n",
       ".transformer.h.2_feature15              0.556673      2       15\n",
       ".transformer.h.0_feature4               0.470279      0        4\n",
       ".transformer.h.0_feature6               0.447680      0        6\n",
       ".transformer.h.4_feature7               0.390438      4        7\n",
       ".transformer.h.0_feature18              0.378467      0       18\n",
       ".transformer.h.4_feature14              0.316718      4       14\n",
       ".transformer.h.4_feature9               0.272719      4        9\n",
       ".transformer.h.4_feature10              0.228020      4       10\n",
       ".transformer.h.2_feature13              0.167355      2       13\n",
       ".transformer.h.2_feature5               0.095751      2        5\n",
       ".transformer.h.4_feature2               0.023048      4        2\n",
       ".transformer.h.0_feature15             -0.060541      0       15"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_dir = \"/mnt/ssd-1/gpaulo/SAE-Zoology/results/gpt2_simulation/all_at_once\"\n",
    "results = dict()\n",
    "for fname in Path(results_dir).iterdir():\n",
    "    with open(fname, \"r\") as f:\n",
    "        r = json.load(f)\n",
    "    last = fname.stem.split(\".\")[-1]\n",
    "    layer = int(last.split(\"_\")[0])\n",
    "    feat = int(last[last.index(\"_feature\") + len(\"_feature\"):])\n",
    "    results[fname.stem] = {\"ev_correlation_score\": r[\"ev_correlation_score\"], \"layer\": layer, \"feature\": feat}\n",
    "input_scores_df = pd.DataFrame(results).T\n",
    "input_scores_df[\"layer\"] = input_scores_df[\"layer\"].astype(int)\n",
    "input_scores_df[\"feature\"] = input_scores_df[\"feature\"].astype(int)\n",
    "input_scores_df = input_scores_df.sort_values(\"ev_correlation_score\", ascending=False)\n",
    "unq_layers = input_scores_df[\"layer\"].unique()\n",
    "input_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"pile.jsonl\", \"r\") as f:\n",
    "    pile = random.sample([json.loads(line) for line in f.readlines()], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.conda/envs/autointerp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alex/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = \"cuda:0\"\n",
    "\n",
    "subject_name = \"gpt2\"\n",
    "subject = AutoModelForCausalLM.from_pretrained(subject_name).to(device)\n",
    "subject_tokenizer = AutoTokenizer.from_pretrained(subject_name)\n",
    "subject_tokenizer.pad_token = subject_tokenizer.eos_token\n",
    "subject.config.pad_token_id = subject_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "scorer_name = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "scorer = AutoModelForCausalLM.from_pretrained(scorer_name).to(torch.bfloat16).to(device)\n",
    "scorer_tokenizer = AutoTokenizer.from_pretrained(scorer_name)\n",
    "scorer_tokenizer.pad_token = scorer_tokenizer.eos_token\n",
    "scorer.config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "scorer.generation_config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "\n",
    "# explainer is the same model as the scorer\n",
    "explainer = scorer\n",
    "explainer_tokenizer = scorer_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\n",
      "\n",
      "For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\n",
      "\n",
      "The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\n",
      "\n",
      "Neuron 1\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.5)\n",
      "\n",
      "Explanation: fruits\n",
      "\n",
      "Neuron 2\n",
      "<PROMPT>Once upon a time</PROMPT>\n",
      "Most increased tokens: ' there was' (+0.22), ' a' (+0.2), ' a time' (+0.05)\n",
      "\n",
      "Explanation: storytelling\n",
      "\n",
      "Neuron 3\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT>\n",
      "Most increased tokens: ' hers' (+0.09), ' hers' (+0.06), ' hers' (+0.06)\n",
      "\n",
      "<PROMPT>For some reason</PROMPT>\n",
      "Most increased tokens: ' she' (+0.14), ' her' (+0.01), ' hers' (+0.01)\n",
      "\n",
      "<PROMPT>insurance does not cover</PROMPT>\n",
      "Most increased tokens: ' her' (+0.1), ' women' (+0.02), ' her's' (+0.01)\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "\n",
      "Neuron 4\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.5)\n",
      "\n",
      "Explanation: \n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import copy\n",
    "\n",
    "@dataclass\n",
    "class ExplainerInterventionExample:\n",
    "    prompt: str\n",
    "    top_tokens: list[str]\n",
    "    top_p_increases: list[float]\n",
    "\n",
    "    def text(self) -> str:\n",
    "        tokens_str = \", \".join(f\"'{tok}' (+{round(p, 3)})\" for tok, p in zip(self.top_tokens, self.top_p_increases))\n",
    "        return f\"<PROMPT>{self.prompt}</PROMPT>\\nMost increased tokens: {tokens_str}\"\n",
    "    \n",
    "@dataclass\n",
    "class ExplainerNeuronFormatter:\n",
    "    intervention_examples: list[ExplainerInterventionExample]\n",
    "    explanation: str | None = None\n",
    "\n",
    "    def text(self) -> str:\n",
    "        text = \"\\n\\n\".join(example.text() for example in self.intervention_examples)\n",
    "        text += \"\\n\\nExplanation: \"\n",
    "        if self.explanation is not None:\n",
    "            text += self.explanation\n",
    "        return text\n",
    "\n",
    "\n",
    "def get_explainer_prompt(neuron_prompter: ExplainerNeuronFormatter, few_shot_examples: list[ExplainerNeuronFormatter] | None = None) -> str:\n",
    "    prompt = \"We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\\n\\n\" \\\n",
    "        \"For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\\n\\n\" \\\n",
    "        \"The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\\n\\n\"\n",
    "    \n",
    "    i = 1\n",
    "    for few_shot_example in few_shot_examples or []:\n",
    "        assert few_shot_example.explanation is not None\n",
    "        prompt += f\"Neuron {i}\\n\" + few_shot_example.text() + \"\\n\\n\"\n",
    "        i += 1\n",
    "\n",
    "    prompt += f\"Neuron {i}\\n\"\n",
    "    prompt += neuron_prompter.text()\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "fs_examples = [\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"My favorite food is\",\n",
    "                top_tokens=[\" oranges\", \" bananas\", \" apples\"],\n",
    "                top_p_increases=[0.81, 0.09, 0.02]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Whenever I would see\",\n",
    "                top_tokens=[\" fruit\", \" a\", \" apples\", \" red\"],\n",
    "                top_p_increases=[0.09, 0.06, 0.06, 0.5]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"fruits\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Once upon a time\",\n",
    "                top_tokens=[\" there was\", \" a\", \" a time\"],\n",
    "                top_p_increases=[0.22, 0.2, 0.05]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"storytelling\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"He owned the watch for a long time. While he never said it was\",\n",
    "                top_tokens=[\" hers\", \" hers\", \" hers\"],\n",
    "                top_p_increases=[0.09, 0.06, 0.06, 0.5]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"For some reason\",\n",
    "                top_tokens=[\" she\", \" her\", \" hers\"],\n",
    "                top_p_increases=[0.14, 0.01, 0.01]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"insurance does not cover\",\n",
    "                top_tokens=[\" her\", \" women\", \" her's\"],\n",
    "                top_p_increases=[0.10, 0.02, 0.01]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"she/her pronouns\"\n",
    "    )\n",
    "]\n",
    "\n",
    "neuron_prompter = copy.deepcopy(fs_examples[0])\n",
    "neuron_prompter.explanation = None\n",
    "print(get_explainer_prompt(neuron_prompter, fs_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT> oranges\n",
      "\n",
      "Explanation: ateg\n",
      "<PROMPT>From west to east, the westmost of the seven</PROMPT>WAY\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT> hers\n",
      "\n",
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT>\n"
     ]
    }
   ],
   "source": [
    "def get_scorer_simplicity_prompt(explanation):\n",
    "    prefix = \"Explanation\\n\\n\"\n",
    "    return f\"{prefix}{explanation}{scorer_tokenizer.eos_token}\", prefix\n",
    "\n",
    "def get_scorer_predictiveness_prompt(prompt, explanation, few_shot_prompts=None, few_shot_explanations=None, few_shot_tokens=None):\n",
    "    if few_shot_explanations is not None:\n",
    "        assert few_shot_tokens is not None and few_shot_prompts is not None\n",
    "        assert len(few_shot_explanations) == len(few_shot_tokens) == len(few_shot_prompts)\n",
    "        few_shot_prompt = \"\\n\\n\".join(get_scorer_predictiveness_prompt(pr, expl) + token for pr, expl, token in zip(few_shot_prompts, few_shot_explanations, few_shot_tokens)) + \"\\n\\n\"\n",
    "    else:\n",
    "        few_shot_prompt = \"\"\n",
    "    return few_shot_prompt + f\"Explanation: {explanation}\\n<PROMPT>{prompt}</PROMPT>\"\n",
    "\n",
    "few_shot_prompts = [\"My favorite food is\", \"From west to east, the westmost of the seven\", \"He owned the watch for a long time. While he never said it was\"]\n",
    "few_shot_explanations = [\"fruits and vegetables\", \"ateg\", \"she/her pronouns\"]\n",
    "few_shot_tokens = [\" oranges\", \"WAY\", \" hers\"]\n",
    "print(get_scorer_predictiveness_prompt(few_shot_prompts[0], few_shot_explanations[0], few_shot_prompts, few_shot_explanations, few_shot_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def intervene(module, input, output, intervention_strength=10.0, position=-1):\n",
    "    hiddens = output[0]  # the later elements of the tuple are the key value cache\n",
    "    hiddens[:, position, :] += intervention_strength * feat.to(hiddens.device)\n",
    "\n",
    "def get_texts(n, seed=42):\n",
    "    random.seed(seed)\n",
    "    texts = []\n",
    "    for _ in range(n):\n",
    "        # sample a random text from the pile, and stop it at a random token position, less than 64 tokens\n",
    "        text = random.choice(pile)[\"text\"]\n",
    "        text = text.replace(\"\\n\", \"\\\\n\")\n",
    "        tokenized_text = subject_tokenizer.encode(text, add_special_tokens=False, max_length=64, truncation=True)\n",
    "        stop_pos = random.randint(1, min(len(tokenized_text) - 1, 63))\n",
    "        text = subject_tokenizer.decode(tokenized_text[:stop_pos])\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "n_explainer_texts = 3\n",
    "n_scorer_texts = 10\n",
    "# explainer_texts = get_texts(n_explainer_texts)\n",
    "# explainer_texts = [\"Current religion:\", \"A country that is\", \"Many people believe that\"]\n",
    "# scorer_texts = get_texts(n_scorer_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_vocab = scorer_tokenizer.get_vocab()\n",
    "subject_vocab = subject_tokenizer.get_vocab()\n",
    "\n",
    "# Pre-compute the mapping of subject tokens to scorer tokens\n",
    "subject_to_scorer = {}\n",
    "text_subject_to_scorer = {}\n",
    "for subj_tok, subj_id in subject_vocab.items():\n",
    "    if subj_tok in scorer_vocab:\n",
    "        subject_to_scorer[subj_id] = scorer_vocab[subj_tok]\n",
    "        text_subject_to_scorer[subj_tok] = subj_tok\n",
    "    else:\n",
    "        for i in range(len(subj_tok) - 1, 0, -1):\n",
    "            if subj_tok[:i] in scorer_vocab:\n",
    "                subject_to_scorer[subj_id] = scorer_vocab[subj_tok[:i]]\n",
    "                text_subject_to_scorer[subj_tok] = subj_tok[:i]\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"No scorer token found for {subj_tok}\")\n",
    "subject_ids = torch.tensor(list(subject_to_scorer.keys()), device=device)\n",
    "scorer_ids = torch.tensor(list(subject_to_scorer.values()), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae.activation.k=32\n"
     ]
    }
   ],
   "source": [
    "from sae_auto_interp.autoencoders.OpenAI.model import Autoencoder\n",
    "weight_dir = \"/mnt/ssd-1/gpaulo/SAE-Zoology/weights/gpt2_128k\"\n",
    "\n",
    "path = f\"{weight_dir}/{layer}.pt\"\n",
    "state_dict = torch.load(path)\n",
    "ae = Autoencoder.from_state_dict(state_dict=state_dict)\n",
    "print(f\"{ae.activation.k=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top subtexts with highest feature activation:\n",
      "1. Activation: 133.6860\n",
      "   Text: Ak\n",
      "\n",
      "2. Activation: 133.1981\n",
      "   Text: //\n",
      "\n",
      "3. Activation: 133.1981\n",
      "   Text: //\n",
      "\n",
      "4. Activation: 133.0989\n",
      "   Text: Em\n",
      "\n",
      "5. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "6. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "7. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "8. Activation: 132.8722\n",
      "   Text: US\n",
      "\n",
      "9. Activation: 132.8492\n",
      "   Text: K\n",
      "\n",
      "10. Activation: 132.8124\n",
      "   Text: Can\n",
      "\n",
      "11. Activation: 132.7975\n",
      "   Text: Ryan\n",
      "\n",
      "12. Activation: 132.7851\n",
      "   Text: ;\n",
      "\n",
      "13. Activation: 132.6943\n",
      "   Text: G\n",
      "\n",
      "Counter({'1/2/3/4': 2, '2/3': 1, '1,2,3,4,5': 1, '1': 1, '1-2-3-4-5': 1, '2': 1, \"2's\": 1, \"2's, 3's, and 4's\": 1, '1, 2, 3, 4': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.61it/s]\n",
      "  1%|▏         | 1/70 [00:07<08:18,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top subtexts with highest feature activation:\n",
      "1. Activation: 133.6860\n",
      "   Text: Ak\n",
      "\n",
      "2. Activation: 133.1981\n",
      "   Text: //\n",
      "\n",
      "3. Activation: 133.1981\n",
      "   Text: //\n",
      "\n",
      "4. Activation: 133.0989\n",
      "   Text: Em\n",
      "\n",
      "5. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "6. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "7. Activation: 133.0280\n",
      "   Text: 1\n",
      "\n",
      "8. Activation: 132.8722\n",
      "   Text: US\n",
      "\n",
      "9. Activation: 132.8492\n",
      "   Text: K\n",
      "\n",
      "10. Activation: 132.8124\n",
      "   Text: Can\n",
      "\n",
      "11. Activation: 132.7975\n",
      "   Text: Ryan\n",
      "\n",
      "12. Activation: 132.7851\n",
      "   Text: ;\n",
      "\n",
      "13. Activation: 132.6943\n",
      "   Text: G\n",
      "\n",
      "Counter({'2, 3, 4': 4, '2/3/4': 2, \"2, 3, 4, '<|end_of_text|><|begin_of_text|>\\n' (+0.001),'R' (+0.001)\": 1, '2, 3, 4, and The': 1, '3/4 of the most increased tokens are punctuation, indicating the neuron promotes writing style': 1, \"2's, 3's, 4's\": 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.62it/s]\n",
      "  3%|▎         | 2/70 [00:20<11:30, 10.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m         subtext_acts\u001b[38;5;241m.\u001b[39mappend(feat_acts[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# get top k\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Sort subtexts by activation and get top k\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubtext_acts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msubtext_acts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m top_k_indices \u001b[38;5;241m=\u001b[39m sorted_indices[:n_scorer_texts \u001b[38;5;241m+\u001b[39m n_explainer_texts]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Get top k subtexts and their activations\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch\n",
    "from sae_auto_interp.autoencoders.OpenAI.model import Autoencoder\n",
    "from itertools import product\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "weight_dir = \"/mnt/ssd-1/gpaulo/SAE-Zoology/weights/gpt2_128k\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "total_iterations = 10 * 7  # 10 feature indices, 7 layer options\n",
    "for feat_idx, feat_layer in tqdm(product(range(200, 250), [2, 6, 11]), total=total_iterations):\n",
    "    scorer_intervention_strengths = [10, 32, 100, 320, 1000]\n",
    "    explainer_intervention_strength = 32\n",
    "\n",
    "    path = f\"{weight_dir}/{layer}.pt\"\n",
    "    state_dict = torch.load(path)\n",
    "    ae = Autoencoder.from_state_dict(state_dict=state_dict)\n",
    "    feat = ae.decoder.weight[:, feat_idx].to(device)\n",
    "    encoder_feat = ae.encoder.weight[feat_idx, :].to(device)\n",
    "    del ae\n",
    "\n",
    "    # find examples where the feature activates\n",
    "    n_candidate_texts = 100\n",
    "\n",
    "    # Remove any hooks\n",
    "    for l in range(len(subject.transformer.h)):\n",
    "        subject.transformer.h[layer]._forward_hooks.clear()\n",
    "\n",
    "    texts = get_texts(n_candidate_texts)\n",
    "    subtexts = []\n",
    "    subtext_acts = []\n",
    "    for text in texts:\n",
    "        input_ids = subject_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "        with torch.inference_mode():\n",
    "            out = subject(input_ids, output_hidden_states=True)\n",
    "            # hidden_states is actually one longer than the number of layers, because it includes the input embeddings\n",
    "            h = out.hidden_states[layer + 1].squeeze(0)\n",
    "            feat_acts = h @ encoder_feat\n",
    "\n",
    "        for i in range(1, len(feat_acts) + 1):\n",
    "            reassembled_text = subject_tokenizer.decode(input_ids[0, :i])\n",
    "            subtexts.append(reassembled_text)\n",
    "            subtext_acts.append(feat_acts[i - 1])\n",
    "\n",
    "    # get top k\n",
    "    # Sort subtexts by activation and get top k\n",
    "    sorted_indices = sorted(range(len(subtext_acts)), key=lambda i: subtext_acts[i], reverse=True)\n",
    "    top_k_indices = sorted_indices[:n_scorer_texts + n_explainer_texts]\n",
    "\n",
    "    # Get top k subtexts and their activations\n",
    "    top_k_subtexts = [subtexts[i] for i in top_k_indices]\n",
    "    top_k_activations = [subtext_acts[i] for i in top_k_indices]\n",
    "\n",
    "    # Print top k results\n",
    "    print(\"Top subtexts with highest feature activation:\")\n",
    "    for i, (subtext, activation) in enumerate(zip(top_k_subtexts, top_k_activations), 1):\n",
    "        print(f\"{i}. Activation: {activation:.4f}\")\n",
    "        print(f\"   Text: {subtext}\")\n",
    "        print()\n",
    "\n",
    "    random.shuffle(top_k_subtexts)\n",
    "    scorer_texts = top_k_subtexts[:n_scorer_texts]\n",
    "    explainer_texts = top_k_subtexts[n_scorer_texts:]\n",
    "\n",
    "    # get explanation\n",
    "    def get_subject_logits(text, layer, intervention_strength=0.0, position=-1):\n",
    "        for l in range(len(subject.transformer.h)):\n",
    "            subject.transformer.h[l]._forward_hooks.clear()\n",
    "        subject.transformer.h[layer].register_forward_hook(partial(intervene, intervention_strength=intervention_strength, position=-1))\n",
    "\n",
    "        inputs = subject_tokenizer(text, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = subject(**inputs)\n",
    "\n",
    "        return outputs.logits[0, -1, :]\n",
    "\n",
    "    intervention_examples = []\n",
    "    for text in explainer_texts:\n",
    "        clean_logits = get_subject_logits(text, feat_layer, intervention_strength=0.0)\n",
    "        intervened_logits = get_subject_logits(text, feat_layer, intervention_strength=explainer_intervention_strength)\n",
    "        top_probs = (intervened_logits.softmax(dim=-1) - clean_logits.softmax(dim=-1)).topk(10)\n",
    "        # top_logits = intervened_logits.topk(10)\n",
    "        top_tokens = [subject_tokenizer.decode(i) for i in top_probs.indices]\n",
    "        top_p_increases = top_probs.values.tolist()\n",
    "        intervention_examples.append(\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=text,\n",
    "                top_tokens=top_tokens,\n",
    "                top_p_increases=top_p_increases\n",
    "            )\n",
    "        )\n",
    "\n",
    "    neuron_prompter = ExplainerNeuronFormatter(\n",
    "        intervention_examples=intervention_examples\n",
    "    )\n",
    "\n",
    "    # TODO: improve the few-shot examples\n",
    "    explainer_prompt = get_explainer_prompt(neuron_prompter, fs_examples)\n",
    "    explainer_input_ids = explainer_tokenizer(explainer_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    with torch.inference_mode():\n",
    "        samples = explainer.generate(explainer_input_ids, max_new_tokens=100, eos_token_id=explainer_tokenizer.encode(\"\\n\\n\")[-1], num_return_sequences=10)[:, explainer_input_ids.shape[1]:]\n",
    "    explanations = Counter([explainer_tokenizer.decode(sample).split(\"\\n\\n\")[0].strip() for sample in samples])\n",
    "    explanation = explanations.most_common(1)[0][0]\n",
    "    print(explanations)\n",
    "\n",
    "    predictiveness_scores = []\n",
    "    max_intervened_probs = []\n",
    "    for scorer_intervention_strength in tqdm(scorer_intervention_strengths):\n",
    "        \n",
    "        predictiveness_score = torch.tensor(0.0, device=device)\n",
    "        max_intervened_prob = 0.0\n",
    "        \n",
    "        for text in scorer_texts:\n",
    "            \n",
    "            intervened_probs = get_subject_logits(text, feat_layer, intervention_strength=scorer_intervention_strength).softmax(dim=-1)\n",
    "            max_intervened_prob = max(max_intervened_prob, intervened_probs.max().item())\n",
    "\n",
    "            # get the explanation predictiveness\n",
    "            scorer_predictiveness_prompt = get_scorer_predictiveness_prompt(text, explanation, few_shot_prompts, few_shot_explanations, few_shot_tokens)\n",
    "            scorer_input_ids = scorer_tokenizer(scorer_predictiveness_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "            with torch.inference_mode():\n",
    "                scorer_logits = scorer(scorer_input_ids).logits[0, -1, :]\n",
    "                scorer_logp = scorer_logits.log_softmax(dim=-1)\n",
    "            \n",
    "            predictiveness_score += (intervened_probs[subject_ids] * scorer_logp[scorer_ids]).sum()\n",
    "\n",
    "            # Print tokens with high probability (if needed)\n",
    "            # high_prob_mask = intervened_probs > 0.05\n",
    "            # high_prob_tokens = subject_tokenizer.convert_ids_to_tokens(high_prob_mask.nonzero().squeeze())\n",
    "            # high_prob_values = intervened_probs[high_prob_mask]\n",
    "            # for tok, val in zip(high_prob_tokens, high_prob_values):\n",
    "            #     print(tok, val.item())\n",
    "\n",
    "        max_intervened_probs.append(max_intervened_prob)\n",
    "        predictiveness_scores.append(predictiveness_score.item() / len(scorer_texts))\n",
    "        \n",
    "    predictiveness_score = sum(predictiveness_scores) / len(predictiveness_scores)\n",
    "    max_intervened_prob = max(max_intervened_probs)\n",
    "    all_results.append({\n",
    "        \"feat_idx\": feat_idx,\n",
    "        \"feat_layer\": feat_layer,\n",
    "        \"explanation\": explanation,\n",
    "        \"predictiveness_score\": predictiveness_score,\n",
    "        \"intervention_examples\": intervention_examples,\n",
    "        \"max_intervened_prob\": max_intervened_prob,\n",
    "        \"scorer_intervention_strengths\": scorer_intervention_strengths,\n",
    "        \"explainer_intervention_strength\": explainer_intervention_strength,\n",
    "        \"scorer_texts\": scorer_texts,\n",
    "        \"explainer_texts\": explainer_texts,\n",
    "        \"predictiveness_scores\": predictiveness_scores,\n",
    "        \"max_intervened_probs\": max_intervened_probs,\n",
    "    })\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_idx</th>\n",
       "      <th>feat_layer</th>\n",
       "      <th>explanation</th>\n",
       "      <th>predictiveness_score</th>\n",
       "      <th>intervention_examples</th>\n",
       "      <th>max_intervened_prob</th>\n",
       "      <th>scorer_intervention_strengths</th>\n",
       "      <th>explainer_intervention_strength</th>\n",
       "      <th>scorer_texts</th>\n",
       "      <th>explainer_texts</th>\n",
       "      <th>predictiveness_scores</th>\n",
       "      <th>max_intervened_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>182</td>\n",
       "      <td>6</td>\n",
       "      <td>1-2-3-4-0-9</td>\n",
       "      <td>-8.721251</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Road', t...</td>\n",
       "      <td>0.231213</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Project, March, 1, Sim, 2019, 2016, 1, A, Hou...</td>\n",
       "      <td>[Road, A, Value]</td>\n",
       "      <td>[-10.622151947021484, -10.456940460205079, -8....</td>\n",
       "      <td>[0.11679935455322266, 0.1188754290342331, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>-8.875147</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Road', t...</td>\n",
       "      <td>0.226274</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Project, March, 1, Sim, 2019, 2016, 1, A, Hou...</td>\n",
       "      <td>[Road, A, Value]</td>\n",
       "      <td>[-10.631166076660156, -10.523173522949218, -8....</td>\n",
       "      <td>[0.11783038079738617, 0.12202408164739609, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>185</td>\n",
       "      <td>6</td>\n",
       "      <td>2019, value, house</td>\n",
       "      <td>-8.937399</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.431593</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 200, 538, A, A, A, 1, ', 1]</td>\n",
       "      <td>[2019, Value, House]</td>\n",
       "      <td>[-10.816554260253906, -10.416304779052734, -9....</td>\n",
       "      <td>[0.11420270800590515, 0.11989623308181763, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>-8.978640</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.435408</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 200, 538, A, A, A, 1, ', 1]</td>\n",
       "      <td>[2019, Value, House]</td>\n",
       "      <td>[-10.726454925537109, -10.404013061523438, -9....</td>\n",
       "      <td>[0.11452289670705795, 0.12135178595781326, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>-9.364605</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Project'...</td>\n",
       "      <td>0.943791</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Sim, 2019, G, Ay, A, A, A, 200, ', L]</td>\n",
       "      <td>[Project, G, 2016]</td>\n",
       "      <td>[-10.697615814208984, -10.711712646484376, -9....</td>\n",
       "      <td>[0.07175029814243317, 0.06015954166650772, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.192244</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.992656</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Sim, 1, ', A, A, 1, X, A, H]</td>\n",
       "      <td>[2019, 200, House]</td>\n",
       "      <td>[-11.074691772460938, -11.361431121826172, -12...</td>\n",
       "      <td>[0.12653400003910065, 0.16054397821426392, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>134</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.266629</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Sim, 1, ', A, A, 1, X, A, H]</td>\n",
       "      <td>[2019, 200, House]</td>\n",
       "      <td>[-10.987806701660157, -11.11118392944336, -11....</td>\n",
       "      <td>[0.11369820684194565, 0.11930322647094727, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>179</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.326119</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 1, 200, A, A, 1, 538, A, Value]</td>\n",
       "      <td>[2019, ', X]</td>\n",
       "      <td>[-10.844153594970702, -10.966635131835938, -11...</td>\n",
       "      <td>[0.11189045011997223, 0.11463377624750137, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>1-200</td>\n",
       "      <td>-13.544800</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='A', top_...</td>\n",
       "      <td>0.951868</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Road, L, 1, *, A, 538, Value, A, ']</td>\n",
       "      <td>[A, 200, 1]</td>\n",
       "      <td>[-10.737577056884765, -10.89888916015625, -11....</td>\n",
       "      <td>[0.11086613684892654, 0.1106131449341774, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1-1000</td>\n",
       "      <td>-13.582887</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='A', top_...</td>\n",
       "      <td>0.997486</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Road, L, 1, *, A, 538, Value, A, ']</td>\n",
       "      <td>[A, 200, 1]</td>\n",
       "      <td>[-10.897045135498047, -11.134815216064453, -11...</td>\n",
       "      <td>[0.11117079854011536, 0.11355404555797577, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_idx  feat_layer         explanation  predictiveness_score  \\\n",
       "547       182           6         1-2-3-4-0-9             -8.721251   \n",
       "546       182           2             1,2,3,4             -8.875147   \n",
       "556       185           6  2019, value, house             -8.937399   \n",
       "555       185           2                2019             -8.978640   \n",
       "183        61           2                2016             -9.364605   \n",
       "..        ...         ...                 ...                   ...   \n",
       "402       134           2                2019            -13.192244   \n",
       "404       134          11                2019            -13.266629   \n",
       "539       179          11                2019            -13.326119   \n",
       "278        92          11               1-200            -13.544800   \n",
       "276        92           2              1-1000            -13.582887   \n",
       "\n",
       "                                 intervention_examples  max_intervened_prob  \\\n",
       "547  [ExplainerInterventionExample(prompt='Road', t...             0.231213   \n",
       "546  [ExplainerInterventionExample(prompt='Road', t...             0.226274   \n",
       "556  [ExplainerInterventionExample(prompt='2019', t...             0.431593   \n",
       "555  [ExplainerInterventionExample(prompt='2019', t...             0.435408   \n",
       "183  [ExplainerInterventionExample(prompt='Project'...             0.943791   \n",
       "..                                                 ...                  ...   \n",
       "402  [ExplainerInterventionExample(prompt='2019', t...             0.992656   \n",
       "404  [ExplainerInterventionExample(prompt='2019', t...             0.962138   \n",
       "539  [ExplainerInterventionExample(prompt='2019', t...             0.962642   \n",
       "278  [ExplainerInterventionExample(prompt='A', top_...             0.951868   \n",
       "276  [ExplainerInterventionExample(prompt='A', top_...             0.997486   \n",
       "\n",
       "    scorer_intervention_strengths  explainer_intervention_strength  \\\n",
       "547      [10, 32, 100, 320, 1000]                               32   \n",
       "546      [10, 32, 100, 320, 1000]                               32   \n",
       "556      [10, 32, 100, 320, 1000]                               32   \n",
       "555      [10, 32, 100, 320, 1000]                               32   \n",
       "183      [10, 32, 100, 320, 1000]                               32   \n",
       "..                            ...                              ...   \n",
       "402      [10, 32, 100, 320, 1000]                               32   \n",
       "404      [10, 32, 100, 320, 1000]                               32   \n",
       "539      [10, 32, 100, 320, 1000]                               32   \n",
       "278      [10, 32, 100, 320, 1000]                               32   \n",
       "276      [10, 32, 100, 320, 1000]                               32   \n",
       "\n",
       "                                          scorer_texts       explainer_texts  \\\n",
       "547  [Project, March, 1, Sim, 2019, 2016, 1, A, Hou...      [Road, A, Value]   \n",
       "546  [Project, March, 1, Sim, 2019, 2016, 1, A, Hou...      [Road, A, Value]   \n",
       "556              [2016, Q, 200, 538, A, A, A, 1, ', 1]  [2019, Value, House]   \n",
       "555              [2016, Q, 200, 538, A, A, A, 1, ', 1]  [2019, Value, House]   \n",
       "183             [Sim, 2019, G, Ay, A, A, A, 200, ', L]    [Project, G, 2016]   \n",
       "..                                                 ...                   ...   \n",
       "402                [2016, Sim, 1, ', A, A, 1, X, A, H]    [2019, 200, House]   \n",
       "404                [2016, Sim, 1, ', A, A, 1, X, A, H]    [2019, 200, House]   \n",
       "539          [2016, Q, 1, 200, A, A, 1, 538, A, Value]          [2019, ', X]   \n",
       "278         [2016, Road, L, 1, *, A, 538, Value, A, ']           [A, 200, 1]   \n",
       "276         [2016, Road, L, 1, *, A, 538, Value, A, ']           [A, 200, 1]   \n",
       "\n",
       "                                 predictiveness_scores  \\\n",
       "547  [-10.622151947021484, -10.456940460205079, -8....   \n",
       "546  [-10.631166076660156, -10.523173522949218, -8....   \n",
       "556  [-10.816554260253906, -10.416304779052734, -9....   \n",
       "555  [-10.726454925537109, -10.404013061523438, -9....   \n",
       "183  [-10.697615814208984, -10.711712646484376, -9....   \n",
       "..                                                 ...   \n",
       "402  [-11.074691772460938, -11.361431121826172, -12...   \n",
       "404  [-10.987806701660157, -11.11118392944336, -11....   \n",
       "539  [-10.844153594970702, -10.966635131835938, -11...   \n",
       "278  [-10.737577056884765, -10.89888916015625, -11....   \n",
       "276  [-10.897045135498047, -11.134815216064453, -11...   \n",
       "\n",
       "                                  max_intervened_probs  \n",
       "547  [0.11679935455322266, 0.1188754290342331, 0.14...  \n",
       "546  [0.11783038079738617, 0.12202408164739609, 0.1...  \n",
       "556  [0.11420270800590515, 0.11989623308181763, 0.1...  \n",
       "555  [0.11452289670705795, 0.12135178595781326, 0.1...  \n",
       "183  [0.07175029814243317, 0.06015954166650772, 0.4...  \n",
       "..                                                 ...  \n",
       "402  [0.12653400003910065, 0.16054397821426392, 0.1...  \n",
       "404  [0.11369820684194565, 0.11930322647094727, 0.1...  \n",
       "539  [0.11189045011997223, 0.11463377624750137, 0.0...  \n",
       "278  [0.11086613684892654, 0.1106131449341774, 0.08...  \n",
       "276  [0.11117079854011536, 0.11355404555797577, 0.1...  \n",
       "\n",
       "[600 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExplainerInterventionExample(prompt='Road', top_tokens=['-', '1', '2', '.', '/', '(', '4', 'R', '3', 'I'], top_p_increases=[0.02295052632689476, 0.009246092289686203, 0.007624265272170305, 0.006824463605880737, 0.006669001653790474, 0.003991384990513325, 0.0035209404304623604, 0.0030987514182925224, 0.003035462461411953, 0.0026108790189027786]),\n",
       " ExplainerInterventionExample(prompt='A', top_tokens=['-', '.', '1', '2', '/', '4', 'I', '0', '9', '3'], top_p_increases=[0.01804528199136257, 0.013529673218727112, 0.011766989715397358, 0.007346044294536114, 0.005036055110394955, 0.004025498405098915, 0.003730517579242587, 0.003692652564495802, 0.003685819683596492, 0.003536658128723502]),\n",
       " ExplainerInterventionExample(prompt='Value', top_tokens=['-', '.', '1', '2', '(', '/', '0', '4', '3', ':'], top_p_increases=[0.018474796786904335, 0.012588724493980408, 0.011959636583924294, 0.008491882123053074, 0.007572157308459282, 0.006167306564748287, 0.004818673245608807, 0.0037697781808674335, 0.003703588154166937, 0.0034622959792613983])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "all_df.iloc[0].intervention_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.DataFrame(all_results)\n",
    "all_df = all_df.sort_values(\"predictiveness_score\", ascending=False)\n",
    "all_df.to_pickle(f\"counterfactual_results/3layers_200feats.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_idx</th>\n",
       "      <th>feat_layer</th>\n",
       "      <th>explanation</th>\n",
       "      <th>predictiveness_score</th>\n",
       "      <th>intervention_examples</th>\n",
       "      <th>max_intervened_prob</th>\n",
       "      <th>scorer_intervention_strengths</th>\n",
       "      <th>explainer_intervention_strength</th>\n",
       "      <th>scorer_texts</th>\n",
       "      <th>explainer_texts</th>\n",
       "      <th>predictiveness_scores</th>\n",
       "      <th>max_intervened_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>182</td>\n",
       "      <td>6</td>\n",
       "      <td>1-2-3-4-0-9</td>\n",
       "      <td>-8.721251</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Road', t...</td>\n",
       "      <td>0.231213</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Project, March, 1, Sim, 2019, 2016, 1, A, Hou...</td>\n",
       "      <td>[Road, A, Value]</td>\n",
       "      <td>[-10.622151947021484, -10.456940460205079, -8....</td>\n",
       "      <td>[0.11679935455322266, 0.1188754290342331, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>182</td>\n",
       "      <td>2</td>\n",
       "      <td>1,2,3,4</td>\n",
       "      <td>-8.875147</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Road', t...</td>\n",
       "      <td>0.226274</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Project, March, 1, Sim, 2019, 2016, 1, A, Hou...</td>\n",
       "      <td>[Road, A, Value]</td>\n",
       "      <td>[-10.631166076660156, -10.523173522949218, -8....</td>\n",
       "      <td>[0.11783038079738617, 0.12202408164739609, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>185</td>\n",
       "      <td>6</td>\n",
       "      <td>2019, value, house</td>\n",
       "      <td>-8.937399</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.431593</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 200, 538, A, A, A, 1, ', 1]</td>\n",
       "      <td>[2019, Value, House]</td>\n",
       "      <td>[-10.816554260253906, -10.416304779052734, -9....</td>\n",
       "      <td>[0.11420270800590515, 0.11989623308181763, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>-8.978640</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.435408</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 200, 538, A, A, A, 1, ', 1]</td>\n",
       "      <td>[2019, Value, House]</td>\n",
       "      <td>[-10.726454925537109, -10.404013061523438, -9....</td>\n",
       "      <td>[0.11452289670705795, 0.12135178595781326, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>-9.364605</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='Project'...</td>\n",
       "      <td>0.943791</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[Sim, 2019, G, Ay, A, A, A, 200, ', L]</td>\n",
       "      <td>[Project, G, 2016]</td>\n",
       "      <td>[-10.697615814208984, -10.711712646484376, -9....</td>\n",
       "      <td>[0.07175029814243317, 0.06015954166650772, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.192244</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.992656</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Sim, 1, ', A, A, 1, X, A, H]</td>\n",
       "      <td>[2019, 200, House]</td>\n",
       "      <td>[-11.074691772460938, -11.361431121826172, -12...</td>\n",
       "      <td>[0.12653400003910065, 0.16054397821426392, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>134</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.266629</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.962138</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Sim, 1, ', A, A, 1, X, A, H]</td>\n",
       "      <td>[2019, 200, House]</td>\n",
       "      <td>[-10.987806701660157, -11.11118392944336, -11....</td>\n",
       "      <td>[0.11369820684194565, 0.11930322647094727, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>179</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>-13.326119</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='2019', t...</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Q, 1, 200, A, A, 1, 538, A, Value]</td>\n",
       "      <td>[2019, ', X]</td>\n",
       "      <td>[-10.844153594970702, -10.966635131835938, -11...</td>\n",
       "      <td>[0.11189045011997223, 0.11463377624750137, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>1-200</td>\n",
       "      <td>-13.544800</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='A', top_...</td>\n",
       "      <td>0.951868</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Road, L, 1, *, A, 538, Value, A, ']</td>\n",
       "      <td>[A, 200, 1]</td>\n",
       "      <td>[-10.737577056884765, -10.89888916015625, -11....</td>\n",
       "      <td>[0.11086613684892654, 0.1106131449341774, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1-1000</td>\n",
       "      <td>-13.582887</td>\n",
       "      <td>[ExplainerInterventionExample(prompt='A', top_...</td>\n",
       "      <td>0.997486</td>\n",
       "      <td>[10, 32, 100, 320, 1000]</td>\n",
       "      <td>32</td>\n",
       "      <td>[2016, Road, L, 1, *, A, 538, Value, A, ']</td>\n",
       "      <td>[A, 200, 1]</td>\n",
       "      <td>[-10.897045135498047, -11.134815216064453, -11...</td>\n",
       "      <td>[0.11117079854011536, 0.11355404555797577, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_idx  feat_layer         explanation  predictiveness_score  \\\n",
       "547       182           6         1-2-3-4-0-9             -8.721251   \n",
       "546       182           2             1,2,3,4             -8.875147   \n",
       "556       185           6  2019, value, house             -8.937399   \n",
       "555       185           2                2019             -8.978640   \n",
       "183        61           2                2016             -9.364605   \n",
       "..        ...         ...                 ...                   ...   \n",
       "402       134           2                2019            -13.192244   \n",
       "404       134          11                2019            -13.266629   \n",
       "539       179          11                2019            -13.326119   \n",
       "278        92          11               1-200            -13.544800   \n",
       "276        92           2              1-1000            -13.582887   \n",
       "\n",
       "                                 intervention_examples  max_intervened_prob  \\\n",
       "547  [ExplainerInterventionExample(prompt='Road', t...             0.231213   \n",
       "546  [ExplainerInterventionExample(prompt='Road', t...             0.226274   \n",
       "556  [ExplainerInterventionExample(prompt='2019', t...             0.431593   \n",
       "555  [ExplainerInterventionExample(prompt='2019', t...             0.435408   \n",
       "183  [ExplainerInterventionExample(prompt='Project'...             0.943791   \n",
       "..                                                 ...                  ...   \n",
       "402  [ExplainerInterventionExample(prompt='2019', t...             0.992656   \n",
       "404  [ExplainerInterventionExample(prompt='2019', t...             0.962138   \n",
       "539  [ExplainerInterventionExample(prompt='2019', t...             0.962642   \n",
       "278  [ExplainerInterventionExample(prompt='A', top_...             0.951868   \n",
       "276  [ExplainerInterventionExample(prompt='A', top_...             0.997486   \n",
       "\n",
       "    scorer_intervention_strengths  explainer_intervention_strength  \\\n",
       "547      [10, 32, 100, 320, 1000]                               32   \n",
       "546      [10, 32, 100, 320, 1000]                               32   \n",
       "556      [10, 32, 100, 320, 1000]                               32   \n",
       "555      [10, 32, 100, 320, 1000]                               32   \n",
       "183      [10, 32, 100, 320, 1000]                               32   \n",
       "..                            ...                              ...   \n",
       "402      [10, 32, 100, 320, 1000]                               32   \n",
       "404      [10, 32, 100, 320, 1000]                               32   \n",
       "539      [10, 32, 100, 320, 1000]                               32   \n",
       "278      [10, 32, 100, 320, 1000]                               32   \n",
       "276      [10, 32, 100, 320, 1000]                               32   \n",
       "\n",
       "                                          scorer_texts       explainer_texts  \\\n",
       "547  [Project, March, 1, Sim, 2019, 2016, 1, A, Hou...      [Road, A, Value]   \n",
       "546  [Project, March, 1, Sim, 2019, 2016, 1, A, Hou...      [Road, A, Value]   \n",
       "556              [2016, Q, 200, 538, A, A, A, 1, ', 1]  [2019, Value, House]   \n",
       "555              [2016, Q, 200, 538, A, A, A, 1, ', 1]  [2019, Value, House]   \n",
       "183             [Sim, 2019, G, Ay, A, A, A, 200, ', L]    [Project, G, 2016]   \n",
       "..                                                 ...                   ...   \n",
       "402                [2016, Sim, 1, ', A, A, 1, X, A, H]    [2019, 200, House]   \n",
       "404                [2016, Sim, 1, ', A, A, 1, X, A, H]    [2019, 200, House]   \n",
       "539          [2016, Q, 1, 200, A, A, 1, 538, A, Value]          [2019, ', X]   \n",
       "278         [2016, Road, L, 1, *, A, 538, Value, A, ']           [A, 200, 1]   \n",
       "276         [2016, Road, L, 1, *, A, 538, Value, A, ']           [A, 200, 1]   \n",
       "\n",
       "                                 predictiveness_scores  \\\n",
       "547  [-10.622151947021484, -10.456940460205079, -8....   \n",
       "546  [-10.631166076660156, -10.523173522949218, -8....   \n",
       "556  [-10.816554260253906, -10.416304779052734, -9....   \n",
       "555  [-10.726454925537109, -10.404013061523438, -9....   \n",
       "183  [-10.697615814208984, -10.711712646484376, -9....   \n",
       "..                                                 ...   \n",
       "402  [-11.074691772460938, -11.361431121826172, -12...   \n",
       "404  [-10.987806701660157, -11.11118392944336, -11....   \n",
       "539  [-10.844153594970702, -10.966635131835938, -11...   \n",
       "278  [-10.737577056884765, -10.89888916015625, -11....   \n",
       "276  [-10.897045135498047, -11.134815216064453, -11...   \n",
       "\n",
       "                                  max_intervened_probs  \n",
       "547  [0.11679935455322266, 0.1188754290342331, 0.14...  \n",
       "546  [0.11783038079738617, 0.12202408164739609, 0.1...  \n",
       "556  [0.11420270800590515, 0.11989623308181763, 0.1...  \n",
       "555  [0.11452289670705795, 0.12135178595781326, 0.1...  \n",
       "183  [0.07175029814243317, 0.06015954166650772, 0.4...  \n",
       "..                                                 ...  \n",
       "402  [0.12653400003910065, 0.16054397821426392, 0.1...  \n",
       "404  [0.11369820684194565, 0.11930322647094727, 0.1...  \n",
       "539  [0.11189045011997223, 0.11463377624750137, 0.0...  \n",
       "278  [0.11086613684892654, 0.1106131449341774, 0.08...  \n",
       "276  [0.11117079854011536, 0.11355404555797577, 0.1...  \n",
       "\n",
       "[600 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_pickle(f\"counterfactual_results/3layers_200feats.pkl\")\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# get explanation\n",
    "def get_subject_logits(text, layer, intervention_strength=0.0, position=-1):\n",
    "    for l in range(len(subject.transformer.h)):\n",
    "        subject.transformer.h[l]._forward_hooks.clear()\n",
    "    subject.transformer.h[layer].register_forward_hook(partial(intervene, intervention_strength=intervention_strength, position=-1))\n",
    "\n",
    "    inputs = subject_tokenizer(text, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = subject(**inputs)\n",
    "\n",
    "    return outputs.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2020 Democratic candidates': 2, '2020 presidential candidates': 2, '2020 US presidential candidate Andrew Yang': 1, '2020 Democratic presidential candidates': 1, '2020 Democratic presidential candidate Andrew Yang': 1, '2020 presidential candidates Yang, Siren, Kali, Az, Li, and Karin': 1, '2020 presidential candidates Andrew Yang, Tulsi Gabbard, and Pete Buttigieg': 1, '2020 presidential candidate Andrew Yang': 1})\n"
     ]
    }
   ],
   "source": [
    "intervention_examples = []\n",
    "for text in explainer_texts:\n",
    "    clean_logits = get_subject_logits(text, feat_layer, intervention_strength=0.0)\n",
    "    intervened_logits = get_subject_logits(text, feat_layer, intervention_strength=explainer_intervention_strength)\n",
    "    top_probs = (intervened_logits.softmax(dim=-1) - clean_logits.softmax(dim=-1)).topk(10)\n",
    "    # top_logits = intervened_logits.topk(10)\n",
    "    top_tokens = [subject_tokenizer.decode(i) for i in top_probs.indices]\n",
    "    top_p_increases = top_probs.values.tolist()\n",
    "    intervention_examples.append(\n",
    "        ExplainerInterventionExample(\n",
    "            prompt=text,\n",
    "            top_tokens=top_tokens,\n",
    "            top_p_increases=top_p_increases\n",
    "        )\n",
    "    )\n",
    "\n",
    "neuron_prompter = ExplainerNeuronFormatter(\n",
    "    intervention_examples=intervention_examples\n",
    ")\n",
    "\n",
    "# TODO: improve the few-shot examples\n",
    "explainer_prompt = get_explainer_prompt(neuron_prompter, fs_examples)\n",
    "explainer_input_ids = explainer_tokenizer(explainer_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "with torch.inference_mode():\n",
    "    samples = explainer.generate(explainer_input_ids, max_new_tokens=100, eos_token_id=explainer_tokenizer.encode(\"\\n\\n\")[-1], num_return_sequences=10)[:, explainer_input_ids.shape[1]:]\n",
    "explanations = Counter([explainer_tokenizer.decode(sample).split(\"\\n\\n\")[0].strip() for sample in samples])\n",
    "explanation = explanations.most_common(1)[0][0]\n",
    "print(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = explainer.generate(explainer_input_ids, max_new_tokens=100, eos_token_id=explainer_tokenizer.encode(\"\\n\\n\")[-1], num_return_sequences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\n",
      "\n",
      "For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\n",
      "\n",
      "The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\n",
      "\n",
      "Neuron 1\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens:'oranges' (+0.81),'bananas' (+0.09),'apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens:'fruit' (+0.09),'a' (+0.06),'apples' (+0.06),'red' (+0.5)\n",
      "\n",
      "Explanation: fruits\n",
      "\n",
      "Neuron 2\n",
      "<PROMPT>Once upon a time</PROMPT>\n",
      "Most increased tokens:'there was' (+0.22),'a' (+0.2),'a time' (+0.05)\n",
      "\n",
      "Explanation: storytelling\n",
      "\n",
      "Neuron 3\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT>\n",
      "Most increased tokens:'hers' (+0.09),'hers' (+0.06),'hers' (+0.06)\n",
      "\n",
      "<PROMPT>For some reason</PROMPT>\n",
      "Most increased tokens:'she' (+0.14),'her' (+0.01),'hers' (+0.01)\n",
      "\n",
      "<PROMPT>insurance does not cover</PROMPT>\n",
      "Most increased tokens:'her' (+0.1),'women' (+0.02),'her's' (+0.01)\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "\n",
      "Neuron 4\n",
      "<PROMPT>Ryan Quarles\\n\\nRyan Francis Quarles (born October 20, 1983) is an American politician and member of the Republican Party from the Commonwealth of Kentucky who has served as Agriculture Commissioner of Kentucky since</PROMPT>\n",
      "Most increased tokens:'D' (+0.185),'Yang' (+0.14),'Az' (+0.061),'Karin' (+0.055),'Yuk' (+0.051),'Li' (+0.045),'Kali' (+0.044),'Siren' (+0.04),'U' (+0.036),'Vaj' (+0.031)\n",
      "\n",
      "<PROMPT>MSI Going Full Throttle @ CeBIT in Germany\\n\\nОбновлено:Wed,</PROMPT>\n",
      "Most increased tokens:'Yang' (+0.178),'D' (+0.16),'Siren' (+0.101),'Az' (+0.067),'Kali' (+0.063),'Yuk' (+0.055),'Li' (+0.04),'Karin' (+0.025),'Vaj' (+0.024),'U' (+0.022)\n",
      "\n",
      "<PROMPT>Getty Images\\n\\nRelated Zombie Tax Lies New York Times\\n\\nYou may imagine tax law professor’s life as the very picture of tedium: days filled with analyzing arcane regulations and number crunching. And</PROMPT>\n",
      "Most increased tokens:'Yang' (+0.204),'D' (+0.114),'Siren' (+0.106),'Az' (+0.063),'Yuk' (+0.049),'Kali' (+0.046),'Li' (+0.045),'Karin' (+0.034),'U' (+0.024),'Vaj' (+0.021)\n",
      "\n",
      "Explanation: 2020 Democratic candidates\n",
      "\n",
      "<|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(explainer_tokenizer.decode(samples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:01,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:01,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-8.572526245117189"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "predictiveness_scores = []\n",
    "max_intervened_probs = []\n",
    "for scorer_intervention_strength in tqdm(scorer_intervention_strengths):\n",
    "    \n",
    "    predictiveness_score = torch.tensor(0.0, device=device)\n",
    "    max_intervened_prob = 0.0\n",
    "    total_inference_time = 0\n",
    "    total_loop_time = 0\n",
    "    for text in scorer_texts:\n",
    "        inference_start = time.time()\n",
    "        intervened_probs = get_subject_logits(text, feat_layer, intervention_strength=scorer_intervention_strength).softmax(dim=-1)\n",
    "        max_intervened_prob = max(max_intervened_prob, intervened_probs.max().item())\n",
    "\n",
    "        # get the explanation predictiveness\n",
    "        scorer_predictiveness_prompt = get_scorer_predictiveness_prompt(text, explanation, few_shot_prompts, few_shot_explanations, few_shot_tokens)\n",
    "        scorer_input_ids = scorer_tokenizer(scorer_predictiveness_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "        with torch.inference_mode():\n",
    "            scorer_logits = scorer(scorer_input_ids).logits[0, -1, :]\n",
    "            scorer_logp = scorer_logits.log_softmax(dim=-1)\n",
    "        inference_end = time.time()\n",
    "        total_inference_time += inference_end - inference_start\n",
    "\n",
    "        loop_start = time.time()\n",
    "\n",
    "        predictiveness_score += (intervened_probs[subject_ids] * scorer_logp[scorer_ids]).sum()\n",
    "\n",
    "        # Print tokens with high probability (if needed)\n",
    "        high_prob_mask = intervened_probs > 0.05\n",
    "        # high_prob_tokens = subject_tokenizer.convert_ids_to_tokens(high_prob_mask.nonzero().squeeze())\n",
    "        # high_prob_values = intervened_probs[high_prob_mask]\n",
    "        # for tok, val in zip(high_prob_tokens, high_prob_values):\n",
    "        #     print(tok, val.item())\n",
    "\n",
    "        loop_end = time.time()\n",
    "        total_loop_time += loop_end - loop_start\n",
    "    max_intervened_probs.append(max_intervened_prob)\n",
    "    predictiveness_scores.append(predictiveness_score.item() / len(scorer_texts))\n",
    "    \n",
    "    print(f\"Total inference time: {total_inference_time:.2f} seconds\")\n",
    "    print(f\"Total innermost loop time: {total_loop_time:.2f} seconds\")\n",
    "\n",
    "predictiveness_score = sum(predictiveness_scores) / len(predictiveness_scores)\n",
    "predictiveness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3747e-08, 1.0227e-07, 6.0999e-09,  ..., 6.2786e-12, 7.6808e-13,\n",
       "        1.2035e-07], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervened_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 1984', tensor(0.0322, device='cuda:0')),\n",
       " (' 1986', tensor(0.0288, device='cuda:0')),\n",
       " (' 1987', tensor(0.0286, device='cuda:0')),\n",
       " (' 1981', tensor(0.0269, device='cuda:0')),\n",
       " (' 1983', tensor(0.0249, device='cuda:0')),\n",
       " (' 1985', tensor(0.0237, device='cuda:0')),\n",
       " (' 1980', tensor(0.0235, device='cuda:0')),\n",
       " (' 1982', tensor(0.0225, device='cuda:0')),\n",
       " (' 1989', tensor(0.0219, device='cuda:0')),\n",
       " (' 1988', tensor(0.0212, device='cuda:0'))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = intervened_probs.topk(10)\n",
    "# topk = clean_logits.softmax(dim=-1).topk(10)\n",
    "[(subject_tokenizer.decode(p[0]), p[1]) for p in list(zip(topk.indices, topk.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Islamic', tensor(0.3354, device='cuda:0')),\n",
       " (' Quran', tensor(0.2592, device='cuda:0')),\n",
       " ('abad', tensor(0.1282, device='cuda:0')),\n",
       " (' Sharia', tensor(0.0909, device='cuda:0')),\n",
       " ('uddin', tensor(0.0755, device='cuda:0')),\n",
       " (' holiest', tensor(0.0253, device='cuda:0')),\n",
       " (' Koran', tensor(0.0096, device='cuda:0')),\n",
       " (' Mecca', tensor(0.0094, device='cuda:0')),\n",
       " (' blasphemy', tensor(0.0068, device='cuda:0')),\n",
       " ('Islamic', tensor(0.0067, device='cuda:0'))]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = intervened_probs.topk(10)\n",
    "# topk = clean_logits.softmax(dim=-1).topk(10)\n",
    "[(subject_tokenizer.decode(p[0]), p[1]) for p in list(zip(topk.indices, topk.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9468, device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(topk.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.2017333984375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictiveness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiveness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictiveness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_intervention_strengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autointerp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
