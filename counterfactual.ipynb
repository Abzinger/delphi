{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject model\n",
    "# load SAEs without attaching them to the model\n",
    "# for now just use the Islam feature and explanation\n",
    "# load a scorer. The prompt should have the input as well this time\n",
    "# (for now) on random pretraining data, evaluate gpt2 with a hook that \n",
    "# adds a multiple of the Islam feature to the appropriate residual stream layer and position\n",
    "# Get the pre- and post-intervention output distributions of gpt2\n",
    "# (TODO: check if all the Islam features just have similar embeddings)\n",
    "# Show this to the scorer and get a score (scorer should be able to have a good prior without being given the clean output distribution)\n",
    "# Also get a simplicity score for the explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ev_correlation_score</th>\n",
       "      <th>layer</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature0</th>\n",
       "      <td>0.970093</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature19</th>\n",
       "      <td>0.966378</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature0</th>\n",
       "      <td>0.952401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature4</th>\n",
       "      <td>0.952061</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature5</th>\n",
       "      <td>0.949993</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature4</th>\n",
       "      <td>0.941871</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature11</th>\n",
       "      <td>0.930066</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature19</th>\n",
       "      <td>0.918787</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature14</th>\n",
       "      <td>0.906342</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature3</th>\n",
       "      <td>0.897080</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature11</th>\n",
       "      <td>0.883083</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature9</th>\n",
       "      <td>0.868529</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature3</th>\n",
       "      <td>0.810241</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature18</th>\n",
       "      <td>0.805457</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature16</th>\n",
       "      <td>0.782019</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature11</th>\n",
       "      <td>0.779133</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature10</th>\n",
       "      <td>0.772255</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature7</th>\n",
       "      <td>0.764754</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature7</th>\n",
       "      <td>0.712047</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature12</th>\n",
       "      <td>0.711850</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature0</th>\n",
       "      <td>0.698656</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature12</th>\n",
       "      <td>0.678797</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature15</th>\n",
       "      <td>0.668821</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature13</th>\n",
       "      <td>0.668621</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature1</th>\n",
       "      <td>0.662348</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature2</th>\n",
       "      <td>0.659443</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature13</th>\n",
       "      <td>0.649270</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature3</th>\n",
       "      <td>0.645487</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature6</th>\n",
       "      <td>0.643440</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature17</th>\n",
       "      <td>0.627347</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature8</th>\n",
       "      <td>0.583940</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature15</th>\n",
       "      <td>0.556673</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature4</th>\n",
       "      <td>0.470279</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature6</th>\n",
       "      <td>0.447680</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature7</th>\n",
       "      <td>0.390438</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature18</th>\n",
       "      <td>0.378467</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature14</th>\n",
       "      <td>0.316718</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature9</th>\n",
       "      <td>0.272719</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature10</th>\n",
       "      <td>0.228020</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature13</th>\n",
       "      <td>0.167355</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.2_feature5</th>\n",
       "      <td>0.095751</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.4_feature2</th>\n",
       "      <td>0.023048</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.transformer.h.0_feature15</th>\n",
       "      <td>-0.060541</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ev_correlation_score  layer  feature\n",
       ".transformer.h.2_feature0               0.970093      2        0\n",
       ".transformer.h.2_feature19              0.966378      2       19\n",
       ".transformer.h.0_feature0               0.952401      0        0\n",
       ".transformer.h.4_feature4               0.952061      4        4\n",
       ".transformer.h.0_feature5               0.949993      0        5\n",
       ".transformer.h.2_feature4               0.941871      2        4\n",
       ".transformer.h.2_feature11              0.930066      2       11\n",
       ".transformer.h.4_feature19              0.918787      4       19\n",
       ".transformer.h.0_feature14              0.906342      0       14\n",
       ".transformer.h.0_feature3               0.897080      0        3\n",
       ".transformer.h.0_feature11              0.883083      0       11\n",
       ".transformer.h.0_feature9               0.868529      0        9\n",
       ".transformer.h.2_feature3               0.810241      2        3\n",
       ".transformer.h.2_feature18              0.805457      2       18\n",
       ".transformer.h.0_feature16              0.782019      0       16\n",
       ".transformer.h.4_feature11              0.779133      4       11\n",
       ".transformer.h.0_feature10              0.772255      0       10\n",
       ".transformer.h.0_feature7               0.764754      0        7\n",
       ".transformer.h.2_feature7               0.712047      2        7\n",
       ".transformer.h.0_feature12              0.711850      0       12\n",
       ".transformer.h.4_feature0               0.698656      4        0\n",
       ".transformer.h.4_feature12              0.678797      4       12\n",
       ".transformer.h.4_feature15              0.668821      4       15\n",
       ".transformer.h.4_feature13              0.668621      4       13\n",
       ".transformer.h.2_feature1               0.662348      2        1\n",
       ".transformer.h.2_feature2               0.659443      2        2\n",
       ".transformer.h.0_feature13              0.649270      0       13\n",
       ".transformer.h.4_feature3               0.645487      4        3\n",
       ".transformer.h.2_feature6               0.643440      2        6\n",
       ".transformer.h.4_feature17              0.627347      4       17\n",
       ".transformer.h.4_feature8               0.583940      4        8\n",
       ".transformer.h.2_feature15              0.556673      2       15\n",
       ".transformer.h.0_feature4               0.470279      0        4\n",
       ".transformer.h.0_feature6               0.447680      0        6\n",
       ".transformer.h.4_feature7               0.390438      4        7\n",
       ".transformer.h.0_feature18              0.378467      0       18\n",
       ".transformer.h.4_feature14              0.316718      4       14\n",
       ".transformer.h.4_feature9               0.272719      4        9\n",
       ".transformer.h.4_feature10              0.228020      4       10\n",
       ".transformer.h.2_feature13              0.167355      2       13\n",
       ".transformer.h.2_feature5               0.095751      2        5\n",
       ".transformer.h.4_feature2               0.023048      4        2\n",
       ".transformer.h.0_feature15             -0.060541      0       15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_dir = \"/mnt/ssd-1/gpaulo/SAE-Zoology/results/gpt2_simulation/all_at_once\"\n",
    "results = dict()\n",
    "for fname in Path(results_dir).iterdir():\n",
    "    with open(fname, \"r\") as f:\n",
    "        r = json.load(f)\n",
    "    last = fname.stem.split(\".\")[-1]\n",
    "    layer = int(last.split(\"_\")[0])\n",
    "    feat = int(last[last.index(\"_feature\") + len(\"_feature\"):])\n",
    "    results[fname.stem] = {\"ev_correlation_score\": r[\"ev_correlation_score\"], \"layer\": layer, \"feature\": feat}\n",
    "input_scores_df = pd.DataFrame(results).T\n",
    "input_scores_df[\"layer\"] = input_scores_df[\"layer\"].astype(int)\n",
    "input_scores_df[\"feature\"] = input_scores_df[\"feature\"].astype(int)\n",
    "input_scores_df = input_scores_df.sort_values(\"ev_correlation_score\", ascending=False)\n",
    "unq_layers = input_scores_df[\"layer\"].unique()\n",
    "input_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"pile.jsonl\", \"r\") as f:\n",
    "    pile = random.sample([json.loads(line) for line in f.readlines()], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.conda/envs/autointerp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/alex/.conda/envs/autointerp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = \"cuda:0\"\n",
    "\n",
    "subject_name = \"gpt2\"\n",
    "subject = AutoModelForCausalLM.from_pretrained(subject_name).to(device)\n",
    "subject_tokenizer = AutoTokenizer.from_pretrained(subject_name)\n",
    "subject_tokenizer.pad_token = subject_tokenizer.eos_token\n",
    "subject.config.pad_token_id = subject_tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "scorer_name = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "scorer = AutoModelForCausalLM.from_pretrained(scorer_name).to(torch.bfloat16).to(device)\n",
    "scorer_tokenizer = AutoTokenizer.from_pretrained(scorer_name)\n",
    "scorer_tokenizer.pad_token = scorer_tokenizer.eos_token\n",
    "scorer.config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "scorer.generation_config.pad_token_id = scorer_tokenizer.eos_token_id\n",
    "\n",
    "# explainer is the same model as the scorer\n",
    "explainer = scorer\n",
    "explainer_tokenizer = scorer_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\n",
      "\n",
      "For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\n",
      "\n",
      "The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\n",
      "\n",
      "Neuron 1\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.5)\n",
      "\n",
      "Explanation: fruits\n",
      "\n",
      "Neuron 2\n",
      "<PROMPT>Once upon a time</PROMPT>\n",
      "Most increased tokens: ' there was' (+0.22), ' a' (+0.2), ' a time' (+0.05)\n",
      "\n",
      "Explanation: storytelling\n",
      "\n",
      "Neuron 3\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT>\n",
      "Most increased tokens: ' hers' (+0.09), ' hers' (+0.06), ' hers' (+0.06)\n",
      "\n",
      "<PROMPT>For some reason</PROMPT>\n",
      "Most increased tokens: ' she' (+0.14), ' her' (+0.01), ' hers' (+0.01)\n",
      "\n",
      "<PROMPT>insurance does not cover</PROMPT>\n",
      "Most increased tokens: ' her' (+0.1), ' women' (+0.02), ' her's' (+0.01)\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "\n",
      "Neuron 4\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens: ' oranges' (+0.81), ' bananas' (+0.09), ' apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens: ' fruit' (+0.09), ' a' (+0.06), ' apples' (+0.06), ' red' (+0.5)\n",
      "\n",
      "Explanation: \n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import copy\n",
    "\n",
    "@dataclass\n",
    "class ExplainerInterventionExample:\n",
    "    prompt: str\n",
    "    top_tokens: list[str]\n",
    "    top_p_increases: list[float]\n",
    "\n",
    "    def text(self) -> str:\n",
    "        tokens_str = \", \".join(f\"'{tok}' (+{round(p, 3)})\" for tok, p in zip(self.top_tokens, self.top_p_increases))\n",
    "        return f\"<PROMPT>{self.prompt}</PROMPT>\\nMost increased tokens: {tokens_str}\"\n",
    "    \n",
    "@dataclass\n",
    "class ExplainerNeuronFormatter:\n",
    "    intervention_examples: list[ExplainerInterventionExample]\n",
    "    explanation: str | None = None\n",
    "\n",
    "    def text(self) -> str:\n",
    "        text = \"\\n\\n\".join(example.text() for example in self.intervention_examples)\n",
    "        text += \"\\n\\nExplanation: \"\n",
    "        if self.explanation is not None:\n",
    "            text += self.explanation\n",
    "        return text\n",
    "\n",
    "\n",
    "def get_explainer_prompt(neuron_prompter: ExplainerNeuronFormatter, few_shot_examples: list[ExplainerNeuronFormatter] | None = None) -> str:\n",
    "    prompt = \"We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\\n\\n\" \\\n",
    "        \"For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\\n\\n\" \\\n",
    "        \"The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\\n\\n\"\n",
    "    \n",
    "    i = 1\n",
    "    for few_shot_example in few_shot_examples or []:\n",
    "        assert few_shot_example.explanation is not None\n",
    "        prompt += f\"Neuron {i}\\n\" + few_shot_example.text() + \"\\n\\n\"\n",
    "        i += 1\n",
    "\n",
    "    prompt += f\"Neuron {i}\\n\"\n",
    "    prompt += neuron_prompter.text()\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "fs_examples = [\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"My favorite food is\",\n",
    "                top_tokens=[\" oranges\", \" bananas\", \" apples\"],\n",
    "                top_p_increases=[0.81, 0.09, 0.02]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Whenever I would see\",\n",
    "                top_tokens=[\" fruit\", \" a\", \" apples\", \" red\"],\n",
    "                top_p_increases=[0.09, 0.06, 0.06, 0.5]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"fruits\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"Once upon a time\",\n",
    "                top_tokens=[\" there was\", \" a\", \" a time\"],\n",
    "                top_p_increases=[0.22, 0.2, 0.05]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"storytelling\"\n",
    "    ),\n",
    "    ExplainerNeuronFormatter(\n",
    "        intervention_examples=[\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"He owned the watch for a long time. While he never said it was\",\n",
    "                top_tokens=[\" hers\", \" hers\", \" hers\"],\n",
    "                top_p_increases=[0.09, 0.06, 0.06, 0.5]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"For some reason\",\n",
    "                top_tokens=[\" she\", \" her\", \" hers\"],\n",
    "                top_p_increases=[0.14, 0.01, 0.01]\n",
    "            ),\n",
    "            ExplainerInterventionExample(\n",
    "                prompt=\"insurance does not cover\",\n",
    "                top_tokens=[\" her\", \" women\", \" her's\"],\n",
    "                top_p_increases=[0.10, 0.02, 0.01]\n",
    "            )\n",
    "        ],\n",
    "        explanation=\"she/her pronouns\"\n",
    "    )\n",
    "]\n",
    "\n",
    "neuron_prompter = copy.deepcopy(fs_examples[0])\n",
    "neuron_prompter.explanation = None\n",
    "print(get_explainer_prompt(neuron_prompter, fs_examples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT> oranges\n",
      "\n",
      "Explanation: ateg\n",
      "<PROMPT>From west to east, the westmost of the seven</PROMPT>WAY\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT> hers\n",
      "\n",
      "Explanation: fruits and vegetables\n",
      "<PROMPT>My favorite food is</PROMPT>\n"
     ]
    }
   ],
   "source": [
    "def get_scorer_simplicity_prompt(explanation):\n",
    "    prefix = \"Explanation\\n\\n\"\n",
    "    return f\"{prefix}{explanation}{scorer_tokenizer.eos_token}\", prefix\n",
    "\n",
    "def get_scorer_predictiveness_prompt(prompt, explanation, few_shot_prompts=None, few_shot_explanations=None, few_shot_tokens=None):\n",
    "    if few_shot_explanations is not None:\n",
    "        assert few_shot_tokens is not None and few_shot_prompts is not None\n",
    "        assert len(few_shot_explanations) == len(few_shot_tokens) == len(few_shot_prompts)\n",
    "        few_shot_prompt = \"\\n\\n\".join(get_scorer_predictiveness_prompt(pr, expl) + token for pr, expl, token in zip(few_shot_prompts, few_shot_explanations, few_shot_tokens)) + \"\\n\\n\"\n",
    "    else:\n",
    "        few_shot_prompt = \"\"\n",
    "    return few_shot_prompt + f\"Explanation: {explanation}\\n<PROMPT>{prompt}</PROMPT>\"\n",
    "\n",
    "few_shot_prompts = [\"My favorite food is\", \"From west to east, the westmost of the seven\", \"He owned the watch for a long time. While he never said it was\"]\n",
    "few_shot_explanations = [\"fruits and vegetables\", \"ateg\", \"she/her pronouns\"]\n",
    "few_shot_tokens = [\" oranges\", \"WAY\", \" hers\"]\n",
    "print(get_scorer_predictiveness_prompt(few_shot_prompts[0], few_shot_explanations[0], few_shot_prompts, few_shot_explanations, few_shot_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def intervene(module, input, output, intervention_strength=10.0, position=-1):\n",
    "    hiddens = output[0]  # the later elements of the tuple are the key value cache\n",
    "    hiddens[:, position, :] += intervention_strength * feat.to(hiddens.device)\n",
    "\n",
    "def get_texts(n, seed=42):\n",
    "    random.seed(seed)\n",
    "    texts = []\n",
    "    for _ in range(n):\n",
    "        # sample a random text from the pile, and stop it at a random token position, less than 64 tokens\n",
    "        text = random.choice(pile)[\"text\"]\n",
    "        text = text.replace(\"\\n\", \"\\\\n\")\n",
    "        tokenized_text = subject_tokenizer.encode(text, add_special_tokens=False, max_length=64, truncation=True)\n",
    "        stop_pos = random.randint(1, min(len(tokenized_text) - 1, 63))\n",
    "        text = subject_tokenizer.decode(tokenized_text[:stop_pos])\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "n_explainer_texts = 3\n",
    "n_scorer_texts = 10\n",
    "# explainer_texts = get_texts(n_explainer_texts)\n",
    "# explainer_texts = [\"Current religion:\", \"A country that is\", \"Many people believe that\"]\n",
    "# scorer_texts = get_texts(n_scorer_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_vocab = scorer_tokenizer.get_vocab()\n",
    "subject_vocab = subject_tokenizer.get_vocab()\n",
    "\n",
    "# Pre-compute the mapping of subject tokens to scorer tokens\n",
    "subject_to_scorer = {}\n",
    "text_subject_to_scorer = {}\n",
    "for subj_tok, subj_id in subject_vocab.items():\n",
    "    if subj_tok in scorer_vocab:\n",
    "        subject_to_scorer[subj_id] = scorer_vocab[subj_tok]\n",
    "        text_subject_to_scorer[subj_tok] = subj_tok\n",
    "    else:\n",
    "        for i in range(len(subj_tok) - 1, 0, -1):\n",
    "            if subj_tok[:i] in scorer_vocab:\n",
    "                subject_to_scorer[subj_id] = scorer_vocab[subj_tok[:i]]\n",
    "                text_subject_to_scorer[subj_tok] = subj_tok[:i]\n",
    "                break\n",
    "        else:\n",
    "            raise ValueError(f\"No scorer token found for {subj_tok}\")\n",
    "subject_ids = torch.tensor(list(subject_to_scorer.keys()), device=device)\n",
    "scorer_ids = torch.tensor(list(subject_to_scorer.values()), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sae_auto_interp.autoencoders.OpenAI.model import Autoencoder\n",
    "\n",
    "\n",
    "weight_dir = \"/mnt/ssd-1/gpaulo/SAE-Zoology/weights/gpt2_128k\"\n",
    "\n",
    "feat_layer = 4\n",
    "feat_idx = 9\n",
    "\n",
    "scorer_intervention_strengths = [10, 32, 100, 320, 1000]\n",
    "explainer_intervention_strength = 1000\n",
    "\n",
    "path = f\"{weight_dir}/{layer}.pt\"\n",
    "state_dict = torch.load(path)\n",
    "ae = Autoencoder.from_state_dict(state_dict=state_dict)\n",
    "feat = ae.decoder.weight[:, feat_idx].to(device)\n",
    "encoder_feat = ae.encoder.weight[feat_idx, :].to(device)\n",
    "del ae\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top subtexts with highest feature activation:\n",
      "1. Activation: 37.6937\n",
      "   Text: When you are with the person you love, even the simplest of the dates becomes the best date ever.\n",
      "\n",
      "2. Activation: 37.4998\n",
      "   Text: Ryan Quarles\\n\\nRyan Francis Quarles (born October 20, 1983) is an American politician and member of the Republican Party from the Commonwealth of Kentucky who has served as Agriculture Commissioner of Kentucky since\n",
      "\n",
      "3. Activation: 36.5109\n",
      "   Text: explorations of mindful fatherhood\\n\\nSoccer season is wrapping up for my son, which is a bitter-sweet conclusion to the Fall.\n",
      "\n",
      "4. Activation: 36.2994\n",
      "   Text: Ryan Quarles\\n\\nRyan Francis Quarles (born October\n",
      "\n",
      "5. Activation: 36.1054\n",
      "   Text: This is the moment a lorry driver stopped his truck to help an elderly lady who was struggling to cross the road in Birmingham.\\n\\nThe clip has been viewed on social media millions of times around the world.\\n\\nBut Manilo Wilson doesn't think he's\n",
      "\n",
      "6. Activation: 36.0235\n",
      "   Text: Common Physics Misconceptions\\n\\nWorld’s First Perpetual Motion Machine?Can this machine operate forever? Since at least the 12th century, man has sought to create a perpetual motion machine;\n",
      "\n",
      "7. Activation: 35.7668\n",
      "   Text: Well I was thoroughly enjoying the sound of my Paradigm Studio 80's being driven by my new Torii MKIII w/ Jupitor Caps, when about 2month into it the mid range woofer on the Left spkr blew out.\n",
      "\n",
      "8. Activation: 35.6353\n",
      "   Text: MSI Going Full Throttle @ CeBIT in Germany\\n\\nОбновлено:Wed,\n",
      "\n",
      "9. Activation: 35.3353\n",
      "   Text: Ryan Quarles\\n\\nRyan Francis Quarles (born October 20,\n",
      "\n",
      "10. Activation: 35.1276\n",
      "   Text: I've searched the net for a not too complex audio CW filter and found the work of NM0S at the website of the \"Four State QRP Group\".\n",
      "\n",
      "11. Activation: 34.8102\n",
      "   Text: Q:\\n\\nUnicode-encode issues while sending desktop notification using Python\\n\\nI am fetching latest football scores from a website and sending a notification on the desktop (OS X). I am\n",
      "\n",
      "12. Activation: 34.7343\n",
      "   Text: Getty Images\\n\\nRelated Zombie Tax Lies New York Times\\n\\nYou may imagine tax law professor’s life as the very picture of tedium: days filled with analyzing arcane regulations and number crunching. And\n",
      "\n",
      "13. Activation: 34.6594\n",
      "   Text: Get your Foot in the Door with Keeping Faith\\n\\nFollowing our award-winning Foot in the Door training scheme pilot, Ffilm Cymru are now offering three exciting new opportunities to learn valuable skills on the set of a major TV production.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find examples where the feature activates\n",
    "n_candidate_texts = 100\n",
    "\n",
    "# Remove any existing hooks\n",
    "for l in range(len(subject.transformer.h)):\n",
    "    subject.transformer.h[layer]._forward_hooks.clear()\n",
    "\n",
    "texts = get_texts(n_candidate_texts)\n",
    "subtexts = []\n",
    "subtext_acts = []\n",
    "for text in texts:\n",
    "    input_ids = subject_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    with torch.inference_mode():\n",
    "        out = subject(input_ids, output_hidden_states=True)\n",
    "        # hidden_states is actually one longer than the number of layers, because it includes the input embeddings\n",
    "        h = out.hidden_states[layer + 1].squeeze(0)\n",
    "        feat_acts = h @ encoder_feat\n",
    "\n",
    "    for i in range(1, len(feat_acts) + 1):\n",
    "        reassembled_text = subject_tokenizer.decode(input_ids[0, :i])\n",
    "        subtexts.append(reassembled_text)\n",
    "        subtext_acts.append(feat_acts[i - 1])\n",
    "\n",
    "# get top k\n",
    "# Sort subtexts by activation and get top k\n",
    "sorted_indices = sorted(range(len(subtext_acts)), key=lambda i: subtext_acts[i], reverse=True)\n",
    "top_k_indices = sorted_indices[:n_scorer_texts + n_explainer_texts]\n",
    "\n",
    "# Get top k subtexts and their activations\n",
    "top_k_subtexts = [subtexts[i] for i in top_k_indices]\n",
    "top_k_activations = [subtext_acts[i] for i in top_k_indices]\n",
    "\n",
    "# Print top k results\n",
    "print(\"Top subtexts with highest feature activation:\")\n",
    "for i, (subtext, activation) in enumerate(zip(top_k_subtexts, top_k_activations), 1):\n",
    "    print(f\"{i}. Activation: {activation:.4f}\")\n",
    "    print(f\"   Text: {subtext}\")\n",
    "    print()\n",
    "\n",
    "# Store top k activations for later use\n",
    "top_k_activations_tensor = torch.tensor(top_k_activations, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(top_k_subtexts)\n",
    "scorer_texts = top_k_subtexts[:n_scorer_texts]\n",
    "explainer_texts = top_k_subtexts[n_scorer_texts:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# get explanation\n",
    "def get_subject_logits(text, layer, intervention_strength=0.0, position=-1):\n",
    "    for l in range(len(subject.transformer.h)):\n",
    "        subject.transformer.h[l]._forward_hooks.clear()\n",
    "    subject.transformer.h[layer].register_forward_hook(partial(intervene, intervention_strength=intervention_strength, position=-1))\n",
    "\n",
    "    inputs = subject_tokenizer(text, return_tensors=\"pt\", add_special_tokens=True).to(device)\n",
    "    with torch.inference_mode():\n",
    "        outputs = subject(**inputs)\n",
    "\n",
    "    return outputs.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'2020 Democratic candidates': 2, '2020 presidential candidates': 2, '2020 US presidential candidate Andrew Yang': 1, '2020 Democratic presidential candidates': 1, '2020 Democratic presidential candidate Andrew Yang': 1, '2020 presidential candidates Yang, Siren, Kali, Az, Li, and Karin': 1, '2020 presidential candidates Andrew Yang, Tulsi Gabbard, and Pete Buttigieg': 1, '2020 presidential candidate Andrew Yang': 1})\n"
     ]
    }
   ],
   "source": [
    "intervention_examples = []\n",
    "for text in explainer_texts:\n",
    "    clean_logits = get_subject_logits(text, feat_layer, intervention_strength=0.0)\n",
    "    intervened_logits = get_subject_logits(text, feat_layer, intervention_strength=explainer_intervention_strength)\n",
    "    top_probs = (intervened_logits.softmax(dim=-1) - clean_logits.softmax(dim=-1)).topk(10)\n",
    "    # top_logits = intervened_logits.topk(10)\n",
    "    top_tokens = [subject_tokenizer.decode(i) for i in top_probs.indices]\n",
    "    top_p_increases = top_probs.values.tolist()\n",
    "    intervention_examples.append(\n",
    "        ExplainerInterventionExample(\n",
    "            prompt=text,\n",
    "            top_tokens=top_tokens,\n",
    "            top_p_increases=top_p_increases\n",
    "        )\n",
    "    )\n",
    "\n",
    "neuron_prompter = ExplainerNeuronFormatter(\n",
    "    intervention_examples=intervention_examples\n",
    ")\n",
    "\n",
    "# TODO: improve the few-shot examples\n",
    "explainer_prompt = get_explainer_prompt(neuron_prompter, fs_examples)\n",
    "explainer_input_ids = explainer_tokenizer(explainer_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "with torch.inference_mode():\n",
    "    samples = explainer.generate(explainer_input_ids, max_new_tokens=100, eos_token_id=explainer_tokenizer.encode(\"\\n\\n\")[-1], num_return_sequences=10)[:, explainer_input_ids.shape[1]:]\n",
    "explanations = Counter([explainer_tokenizer.decode(sample).split(\"\\n\\n\")[0].strip() for sample in samples])\n",
    "explanation = explanations.most_common(1)[0][0]\n",
    "print(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = explainer.generate(explainer_input_ids, max_new_tokens=100, eos_token_id=explainer_tokenizer.encode(\"\\n\\n\")[-1], num_return_sequences=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>We're studying neurons in a transformer model. We want to know how intervening on them affects the model's output.\n",
      "\n",
      "For each neuron, we'll show you a few prompts where we intervened on that neuron at the final token position, and the tokens whose logits increased the most.\n",
      "\n",
      "The tokens are shown in descending order of their probability increase, given in parentheses. Your job is to give a short summary of what outputs the neuron promotes.\n",
      "\n",
      "Neuron 1\n",
      "<PROMPT>My favorite food is</PROMPT>\n",
      "Most increased tokens:'oranges' (+0.81),'bananas' (+0.09),'apples' (+0.02)\n",
      "\n",
      "<PROMPT>Whenever I would see</PROMPT>\n",
      "Most increased tokens:'fruit' (+0.09),'a' (+0.06),'apples' (+0.06),'red' (+0.5)\n",
      "\n",
      "Explanation: fruits\n",
      "\n",
      "Neuron 2\n",
      "<PROMPT>Once upon a time</PROMPT>\n",
      "Most increased tokens:'there was' (+0.22),'a' (+0.2),'a time' (+0.05)\n",
      "\n",
      "Explanation: storytelling\n",
      "\n",
      "Neuron 3\n",
      "<PROMPT>He owned the watch for a long time. While he never said it was</PROMPT>\n",
      "Most increased tokens:'hers' (+0.09),'hers' (+0.06),'hers' (+0.06)\n",
      "\n",
      "<PROMPT>For some reason</PROMPT>\n",
      "Most increased tokens:'she' (+0.14),'her' (+0.01),'hers' (+0.01)\n",
      "\n",
      "<PROMPT>insurance does not cover</PROMPT>\n",
      "Most increased tokens:'her' (+0.1),'women' (+0.02),'her's' (+0.01)\n",
      "\n",
      "Explanation: she/her pronouns\n",
      "\n",
      "Neuron 4\n",
      "<PROMPT>Ryan Quarles\\n\\nRyan Francis Quarles (born October 20, 1983) is an American politician and member of the Republican Party from the Commonwealth of Kentucky who has served as Agriculture Commissioner of Kentucky since</PROMPT>\n",
      "Most increased tokens:'D' (+0.185),'Yang' (+0.14),'Az' (+0.061),'Karin' (+0.055),'Yuk' (+0.051),'Li' (+0.045),'Kali' (+0.044),'Siren' (+0.04),'U' (+0.036),'Vaj' (+0.031)\n",
      "\n",
      "<PROMPT>MSI Going Full Throttle @ CeBIT in Germany\\n\\nОбновлено:Wed,</PROMPT>\n",
      "Most increased tokens:'Yang' (+0.178),'D' (+0.16),'Siren' (+0.101),'Az' (+0.067),'Kali' (+0.063),'Yuk' (+0.055),'Li' (+0.04),'Karin' (+0.025),'Vaj' (+0.024),'U' (+0.022)\n",
      "\n",
      "<PROMPT>Getty Images\\n\\nRelated Zombie Tax Lies New York Times\\n\\nYou may imagine tax law professor’s life as the very picture of tedium: days filled with analyzing arcane regulations and number crunching. And</PROMPT>\n",
      "Most increased tokens:'Yang' (+0.204),'D' (+0.114),'Siren' (+0.106),'Az' (+0.063),'Yuk' (+0.049),'Kali' (+0.046),'Li' (+0.045),'Karin' (+0.034),'U' (+0.024),'Vaj' (+0.021)\n",
      "\n",
      "Explanation: 2020 Democratic candidates\n",
      "\n",
      "<|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(explainer_tokenizer.decode(samples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:00<00:01,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:01,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:01<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:01<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total inference time: 0.43 seconds\n",
      "Total innermost loop time: 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-8.572526245117189"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "predictiveness_scores = []\n",
    "max_intervened_probs = []\n",
    "for scorer_intervention_strength in tqdm(scorer_intervention_strengths):\n",
    "    \n",
    "    predictiveness_score = torch.tensor(0.0, device=device)\n",
    "    max_intervened_prob = 0.0\n",
    "    total_inference_time = 0\n",
    "    total_loop_time = 0\n",
    "    for text in scorer_texts:\n",
    "        inference_start = time.time()\n",
    "        intervened_probs = get_subject_logits(text, feat_layer, intervention_strength=scorer_intervention_strength).softmax(dim=-1)\n",
    "        max_intervened_prob = max(max_intervened_prob, intervened_probs.max().item())\n",
    "\n",
    "        # get the explanation predictiveness\n",
    "        scorer_predictiveness_prompt = get_scorer_predictiveness_prompt(text, explanation, few_shot_prompts, few_shot_explanations, few_shot_tokens)\n",
    "        scorer_input_ids = scorer_tokenizer(scorer_predictiveness_prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "        with torch.inference_mode():\n",
    "            scorer_logits = scorer(scorer_input_ids).logits[0, -1, :]\n",
    "            scorer_logp = scorer_logits.log_softmax(dim=-1)\n",
    "        inference_end = time.time()\n",
    "        total_inference_time += inference_end - inference_start\n",
    "\n",
    "        loop_start = time.time()\n",
    "\n",
    "        predictiveness_score += (intervened_probs[subject_ids] * scorer_logp[scorer_ids]).sum()\n",
    "\n",
    "        # Print tokens with high probability (if needed)\n",
    "        high_prob_mask = intervened_probs > 0.05\n",
    "        # high_prob_tokens = subject_tokenizer.convert_ids_to_tokens(high_prob_mask.nonzero().squeeze())\n",
    "        # high_prob_values = intervened_probs[high_prob_mask]\n",
    "        # for tok, val in zip(high_prob_tokens, high_prob_values):\n",
    "        #     print(tok, val.item())\n",
    "\n",
    "        loop_end = time.time()\n",
    "        total_loop_time += loop_end - loop_start\n",
    "    max_intervened_probs.append(max_intervened_prob)\n",
    "    predictiveness_scores.append(predictiveness_score.item() / len(scorer_texts))\n",
    "    \n",
    "    print(f\"Total inference time: {total_inference_time:.2f} seconds\")\n",
    "    print(f\"Total innermost loop time: {total_loop_time:.2f} seconds\")\n",
    "\n",
    "predictiveness_score = sum(predictiveness_scores) / len(predictiveness_scores)\n",
    "predictiveness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3747e-08, 1.0227e-07, 6.0999e-09,  ..., 6.2786e-12, 7.6808e-13,\n",
       "        1.2035e-07], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervened_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 1984', tensor(0.0322, device='cuda:0')),\n",
       " (' 1986', tensor(0.0288, device='cuda:0')),\n",
       " (' 1987', tensor(0.0286, device='cuda:0')),\n",
       " (' 1981', tensor(0.0269, device='cuda:0')),\n",
       " (' 1983', tensor(0.0249, device='cuda:0')),\n",
       " (' 1985', tensor(0.0237, device='cuda:0')),\n",
       " (' 1980', tensor(0.0235, device='cuda:0')),\n",
       " (' 1982', tensor(0.0225, device='cuda:0')),\n",
       " (' 1989', tensor(0.0219, device='cuda:0')),\n",
       " (' 1988', tensor(0.0212, device='cuda:0'))]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = intervened_probs.topk(10)\n",
    "# topk = clean_logits.softmax(dim=-1).topk(10)\n",
    "[(subject_tokenizer.decode(p[0]), p[1]) for p in list(zip(topk.indices, topk.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Islamic', tensor(0.3354, device='cuda:0')),\n",
       " (' Quran', tensor(0.2592, device='cuda:0')),\n",
       " ('abad', tensor(0.1282, device='cuda:0')),\n",
       " (' Sharia', tensor(0.0909, device='cuda:0')),\n",
       " ('uddin', tensor(0.0755, device='cuda:0')),\n",
       " (' holiest', tensor(0.0253, device='cuda:0')),\n",
       " (' Koran', tensor(0.0096, device='cuda:0')),\n",
       " (' Mecca', tensor(0.0094, device='cuda:0')),\n",
       " (' blasphemy', tensor(0.0068, device='cuda:0')),\n",
       " ('Islamic', tensor(0.0067, device='cuda:0'))]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk = intervened_probs.topk(10)\n",
    "# topk = clean_logits.softmax(dim=-1).topk(10)\n",
    "[(subject_tokenizer.decode(p[0]), p[1]) for p in list(zip(topk.indices, topk.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9468, device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(topk.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.2017333984375"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictiveness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiveness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictiveness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer_intervention_strengths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autointerp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
